{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "colab": {
      "name": "nlp_1-5_word_sense_disambiguation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgPmSJ95ix2q"
      },
      "source": [
        "# **Word Sense Disambiguation**\n",
        "\n",
        "Words can have different meanings in different contexts. Sometimes the intended\n",
        "meaning of a word is hard to understand and leads to miscommunication. How does\n",
        "NLP approach this challenge? If a word has multiple meanings, this is called word\n",
        "sense ambiguity. While solving syntactic ambiguity is done with part-of-speech (POS)\n",
        "tagging, solving semantic ambiguity is done with word sense disambiguation (WSD).\n",
        "The challenge is to semantically separate words by their meaning in context [[1]](#scrollTo=fPge5oRLQwid).\n",
        "\n",
        "This notebook shows some basic WSD examples by using the following libraries:\n",
        "* Natural Language Toolkit (NLTK)\n",
        "* Pywsd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Natural Language Toolkit (NLTK)**\n",
        "The Natural Language Toolkit (NLTK) is an open source Python library for Natural Language Processing. For more detail about, NLTK please refer to [[2]](https://www.nltk.org/api/nltk.html#nltk.wsd.lesk)."
      ],
      "metadata": {
        "id": "4NVHzWOj-OpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import WordNet\n",
        "\n",
        "WordNetÂ® is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept. Synsets are interlinked by means of conceptual-semantic and lexical relations [[3]](http://www.nltk.org/howto/wsd.html). "
      ],
      "metadata": {
        "id": "JH715v--MzGy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvXVxIxHjHa5",
        "outputId": "e3f5b6e8-dc33-4818-a55e-68f299fd8524"
      },
      "source": [
        "# Import nltk module\n",
        "import nltk\n",
        "\n",
        "# Download 'wordnet' package by using the nltk module\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Import WordNet class by using the nltk.corpus package\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Lesk\n",
        "The Lesk algorithm is an example of a knowledge-based method and is based on contextual overlap of dictionary definitions. The Lesk algorithm works as follows: We identify the overlapping definitions (underlined in this example) based on the contextual overlap among our Wiktionary definitions referring to the various senses of the ambiguous words. The approach is based on the assumption that words used together are also related to each other [[1]](#scrollTo=fPge5oRLQwid)."
      ],
      "metadata": {
        "id": "BM8WjVjGbzux"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOGMWCyFix3A"
      },
      "source": [
        "# Import lesk library\n",
        "from nltk.wsd import lesk\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPZqdj4Cix3C"
      },
      "source": [
        "### Ambiguation of the word *bank*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfuYxpA3ix3E",
        "outputId": "ea671d8d-21e4-4c3a-96d9-fc7781ab913a"
      },
      "source": [
        "# Create sample text \n",
        "text1 = ['I went to the bank to deposit my money.',\n",
        "              'The river bank was full of dead fishes.']\n",
        "\n",
        "# By using lesk algorithm, anaylze the first sentence and print the definition of the word \"bank\"\n",
        "print( \"=============== analyse sentence 1 =================\\n\")\n",
        "print( \"Context:\", text1[0])\n",
        "answer = lesk(text1[0], 'bank') \n",
        "print( \"Sense:\", answer)\n",
        "print( \"Definition:\",answer.definition())\n",
        "\n",
        "# Anaylze the second sentence and print the definition of the word \"bank\"\n",
        "print( \"\\n\\n=============== analyse sentence 2 =================\\n\")\n",
        "print( \"Context:\", text1[1])\n",
        "answer = lesk(text1[1].split(), 'bank', 'n')\n",
        "print( \"Sense:\", answer)\n",
        "print( \"Definition:\", answer.definition())\n",
        "\n",
        "# For a general overview, print all definitions of the word \"bank\"\n",
        "print( \"\\n\\n=============== all definitions of \\'bank\\'===============\\n\")\n",
        "for s in wn.synsets('bank'):\n",
        "    print('\\t', s, s.definition())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== analyse sentence 1 =================\n",
            "\n",
            "Context: I went to the bank to deposit my money.\n",
            "Sense: Synset('savings_bank.n.02')\n",
            "Definition: a container (usually with a slot in the top) for keeping money at home\n",
            "\n",
            "=============== analyse sentence 2 =================\n",
            "\n",
            "Context: The river bank was full of dead fishes.\n",
            "Sense: Synset('bank.n.09')\n",
            "Definition: a building in which the business of banking transacted\n",
            "\n",
            "=============== all definitions of 'bank'===============\n",
            "\n",
            "\t Synset('bank.n.01') sloping land (especially the slope beside a body of water)\n",
            "\t Synset('depository_financial_institution.n.01') a financial institution that accepts deposits and channels the money into lending activities\n",
            "\t Synset('bank.n.03') a long ridge or pile\n",
            "\t Synset('bank.n.04') an arrangement of similar objects in a row or in tiers\n",
            "\t Synset('bank.n.05') a supply or stock held in reserve for future use (especially in emergencies)\n",
            "\t Synset('bank.n.06') the funds held by a gambling house or the dealer in some gambling games\n",
            "\t Synset('bank.n.07') a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
            "\t Synset('savings_bank.n.02') a container (usually with a slot in the top) for keeping money at home\n",
            "\t Synset('bank.n.09') a building in which the business of banking transacted\n",
            "\t Synset('bank.n.10') a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
            "\t Synset('bank.v.01') tip laterally\n",
            "\t Synset('bank.v.02') enclose with a bank\n",
            "\t Synset('bank.v.03') do business with a bank or keep an account at a bank\n",
            "\t Synset('bank.v.04') act as the banker in a game or in gambling\n",
            "\t Synset('bank.v.05') be in the banking business\n",
            "\t Synset('deposit.v.02') put into a bank account\n",
            "\t Synset('bank.v.07') cover with ashes so to control the rate of burning\n",
            "\t Synset('trust.v.01') have confidence or faith in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swQ-5k8vix3I"
      },
      "source": [
        "### Ambiguation of the word *plant*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9Nf5VAdix3K",
        "outputId": "407a8e91-7842-4197-aa43-2bbd1a58c983"
      },
      "source": [
        "# Create sample text\n",
        "text2 = ['The workers at the industrial plant were overworked.', 'The plant was no longer bearing flowers.']\n",
        "\n",
        "# By using lesk algorithm, anaylze the first sentence and print the definition of the word \"plant\"\n",
        "print( \"=============== analyse sentence 1 =================\\n\")\n",
        "print( \"Context:\", text2[0])\n",
        "answer_1 = lesk(text2[0].split(),'plant','n')\n",
        "print( \"Sense:\", answer_1)\n",
        "print( \"Definition:\",answer_1.definition())\n",
        "\n",
        "# Anaylze the second sentence and print the definition of the word \"plant\"\n",
        "print( \"\\n\\n=============== analyse sentence 2 =================\\n\")\n",
        "print( \"Context:\", text2[1])\n",
        "answer_2 = lesk(text2[1],'plant','n')\n",
        "print( \"Sense:\", answer_2)\n",
        "print( \"Definition:\",answer_2.definition())\n",
        "\n",
        "# For a general overview, print all definitions of the word \"plant\"\n",
        "print( \"\\n\\n=============== all definitions of \\'plant\\'===============\\n\")\n",
        "for s in wn.synsets('plant'):\n",
        "    print('\\t', s, s.definition())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== analyse sentence 1 =================\n",
            "\n",
            "Context: The workers at the industrial plant were overworked.\n",
            "Sense: Synset('plant.n.03')\n",
            "Definition: an actor situated in the audience whose acting is rehearsed but seems spontaneous to the audience\n",
            "\n",
            "=============== analyse sentence 2 =================\n",
            "\n",
            "Context: The plant was no longer bearing flowers.\n",
            "Sense: Synset('plant.n.02')\n",
            "Definition: (botany) a living organism lacking the power of locomotion\n",
            "\n",
            "=============== all definitions of 'plant'===============\n",
            "\n",
            "\t Synset('plant.n.01') buildings for carrying on industrial labor\n",
            "\t Synset('plant.n.02') (botany) a living organism lacking the power of locomotion\n",
            "\t Synset('plant.n.03') an actor situated in the audience whose acting is rehearsed but seems spontaneous to the audience\n",
            "\t Synset('plant.n.04') something planted secretly for discovery by another\n",
            "\t Synset('plant.v.01') put or set (seeds, seedlings, or plants) into the ground\n",
            "\t Synset('implant.v.01') fix or set securely or deeply\n",
            "\t Synset('establish.v.02') set up or lay the groundwork for\n",
            "\t Synset('plant.v.04') place into a river\n",
            "\t Synset('plant.v.05') place something or someone in a certain position in order to secretly observe or deceive\n",
            "\t Synset('plant.v.06') put firmly in the mind\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SLhhgQdix3M"
      },
      "source": [
        "### Ambiguation of the word *fair*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9zShRWZix3N",
        "outputId": "02f6d7df-2310-417e-8189-fbfcb9ebf08f"
      },
      "source": [
        "# Create sample text\n",
        "text3 = ['Everyone needs to be given a fair chance in the competition.', 'The annual fair in our city is next weekend.']\n",
        "\n",
        "# By using lesk algorithm, anaylze the first sentence and print the definition of the word \"fair\"\n",
        "print( \"=============== analyse sentence 1 =================\\n\")\n",
        "print( \"Context:\", text3[0])\n",
        "answer_1 = lesk(text3[0].split(),'fair','n')\n",
        "print( \"Sense:\", answer_1)\n",
        "print( \"Definition:\",answer_1.definition())\n",
        "\n",
        "# Anaylze the second sentence and print the definition of the word \"fair\"\n",
        "print( \"\\n\\n=============== analyse sentence 2 =================\\n\")\n",
        "print( \"Context:\", text3[1])\n",
        "answer_2 = lesk(text3[1],'fair','n')\n",
        "print( \"Sense:\", answer_2)\n",
        "print( \"Definition:\",answer_2.definition())\n",
        "\n",
        "# For a general overview, print all definitions of the word \"fair\"\n",
        "print( \"\\n\\n=============== all definitions of \\'fair\\'===============\\n\")\n",
        "for s in wn.synsets('fair'):\n",
        "    print('\\t', s, s.definition())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== analyse sentence 1 =================\n",
            "\n",
            "Context: Everyone needs to be given a fair chance in the competition.\n",
            "Sense: Synset('fairly.r.02')\n",
            "Definition: without favoring one party, in a fair evenhanded manner\n",
            "\n",
            "=============== analyse sentence 2 =================\n",
            "\n",
            "Context: The annual fair in our city is next weekend.\n",
            "Sense: Synset('fair.n.03')\n",
            "Definition: a competitive exhibition of farm products\n",
            "\n",
            "=============== all definitions of 'fair'===============\n",
            "\n",
            "\t Synset('carnival.n.03') a traveling show; having sideshows and rides and games of skill etc.\n",
            "\t Synset('fair.n.02') gathering of producers to promote business\n",
            "\t Synset('fair.n.03') a competitive exhibition of farm products\n",
            "\t Synset('bazaar.n.03') a sale of miscellany; often for charity\n",
            "\t Synset('fair.v.01') join so that the external surfaces blend smoothly\n",
            "\t Synset('fair.a.01') free from favoritism or self-interest or bias or deception; conforming with established standards or rules\n",
            "\t Synset('fair.s.02') not excessive or extreme\n",
            "\t Synset('bonny.s.01') very pleasing to the eye\n",
            "\t Synset('fair.a.04') (of a baseball) hit between the foul lines\n",
            "\t Synset('average.s.03') lacking exceptional quality or ability\n",
            "\t Synset('fair.s.06') attractively feminine\n",
            "\t Synset('clean.s.11') (of a manuscript) having few alterations or corrections\n",
            "\t Synset('honest.s.07') gained or earned without cheating or stealing\n",
            "\t Synset('fair.s.09') free of clouds or rain\n",
            "\t Synset('fair.s.10') (used of hair or skin) pale or light-colored; \n",
            "\t Synset('fairly.r.03') in conformity with the rules or laws and without fraud or cheating\n",
            "\t Synset('fairly.r.02') without favoring one party, in a fair evenhanded manner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pywsd**\n",
        "Pywsd (Tan, 2014) is a Python library that provides WSD functions as well as several variations of the Lesk algorithm [[1]](#scrollTo=fPge5oRLQwid).\n",
        "\n",
        "For more detail about Pywsd, please refer to [[4]](https://pypi.org/project/pywsd/)."
      ],
      "metadata": {
        "id": "XnvDSfYy-YWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Pywsd package"
      ],
      "metadata": {
        "id": "_csm4xc0R-_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pywsd  "
      ],
      "metadata": {
        "id": "4_feI89HA9Pg",
        "outputId": "4b3475d8-b954-472a-ce3f-872b9d369bee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pywsd\n",
            "  Downloading pywsd-1.2.4.tar.gz (26.8 MB)\n",
            "\u001b[K     |ââââââââââââââââââââââââââââââââ| 26.8 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pywsd) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.3.5)\n",
            "Collecting wn\n",
            "  Downloading wn-0.9.1-py3-none-any.whl (75 kB)\n",
            "\u001b[K     |ââââââââââââââââââââââââââââââââ| 75 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2022.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (4.2.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (2.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (3.0.4)\n",
            "Building wheels for collected packages: pywsd\n",
            "  Building wheel for pywsd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pywsd: filename=pywsd-1.2.4-py3-none-any.whl size=26940436 sha256=836cc295f28edb2f6a965350ebc7647a63a22f59b4db18762ce43ff6d3e37c11\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/67/c0/6e6fa8456d1374b393328368316c3b33844cb4043bd225bc66\n",
            "Successfully built pywsd\n",
            "Installing collected packages: wn, pywsd\n",
            "Successfully installed pywsd-1.2.4 wn-0.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install wn library\n",
        "Wn is a new Python library for working with wordnets. Unlike previous libraries, Wn is built from the beginning to accommodate multiple wordnets (for multiple languages or multiple versions of the same wordnet) while retaining the ability to query and traverse them independently. For more detail about the wn library, please refer to [[5]](https://pypi.org/project/wn/) and [[6]](https://aclanthology.org/2021.gwc-1.12/).\n",
        "\n"
      ],
      "metadata": {
        "id": "FpGN8eXeSFxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wn==0.0.22"
      ],
      "metadata": {
        "id": "YmpRgxijC8oV",
        "outputId": "17a4b2f5-1dcf-4bd5-b680-5816f664ad0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wn==0.0.22\n",
            "  Downloading wn-0.0.22.tar.gz (31.5 MB)\n",
            "\u001b[K     |ââââââââââââââââââââââââââââââââ| 31.5 MB 2.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wn\n",
            "  Building wheel for wn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wn: filename=wn-0.0.22-py3-none-any.whl size=31618484 sha256=7c7e331f14cd62da893d2b1c77d63f41e01628244b9838bc27b4f74b5ec93d71\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/0d/59/4b7902879d8cbad9bb73aaf0cc0a051edc1b18da983889c412\n",
            "Successfully built wn\n",
            "Installing collected packages: wn\n",
            "  Attempting uninstall: wn\n",
            "    Found existing installation: wn 0.9.1\n",
            "    Uninstalling wn-0.9.1:\n",
            "      Successfully uninstalled wn-0.9.1\n",
            "Successfully installed wn-0.0.22\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "wn"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import nltk packages"
      ],
      "metadata": {
        "id": "GdGgQWKKUQok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "B4Hqv8tCMMf3",
        "outputId": "9385609d-bd21-493a-ec32-987fbdf29fbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import simple_lesk module"
      ],
      "metadata": {
        "id": "FHkuushxUcNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simple_lesk returns the sense most suited to the given word as per the Simple LESK Algorithm\n",
        "from pywsd.lesk import simple_lesk  "
      ],
      "metadata": {
        "id": "n2hi79CYBEi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1ce393-985a-4346-bb4e-bc204a17cb9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warming up PyWSD (takes ~10 secs)... took 5.854445934295654 secs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ambiguation of the word *bank*"
      ],
      "metadata": {
        "id": "G2gPMfkNWI8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample text \n",
        "text4 = ['I went to the bank to deposit my money', 'The river bank was full of dead fishes']\n",
        "\n",
        "# Anaylze the first sentence and print the definition of the word \"bank\"\n",
        "print( \"=============== analyse sentence 1 =================\\n\")\n",
        "print (\"Context-1:\", text4[0])  \n",
        "answer = simple_lesk(text4[0],'bank')  \n",
        "print (\"Sense:\", answer)  \n",
        "print (\"Definition : \", answer.definition())  \n",
        "\n",
        "# Anaylze the second sentence and print the definition of the word \"bank\"\n",
        "print( \"\\n\\n=============== analyse sentence 2 =================\\n\")\n",
        "print (\"Context-2:\", text4[1])  \n",
        "answer = simple_lesk(text4[1],'bank')  \n",
        "print (\"Sense:\", answer)  \n",
        "print (\"Definition : \", answer.definition())  "
      ],
      "metadata": {
        "id": "IW471hbAMjJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be5305b4-d8f7-40dc-e4cb-d57e3726a23a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== analyse sentence 1 =================\n",
            "\n",
            "Context-1: I went to the bank to deposit my money\n",
            "Sense: Synset('depository_financial_institution.n.01')\n",
            "Definition :  a financial institution that accepts deposits and channels the money into lending activities\n",
            "\n",
            "\n",
            "=============== analyse sentence 2 =================\n",
            "\n",
            "Context-2: The river bank was full of dead fishes\n",
            "Sense: Synset('bank.n.01')\n",
            "Definition :  sloping land (especially the slope beside a body of water)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ambiguation of the word *plant*"
      ],
      "metadata": {
        "id": "6AD2Aw6uYB1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample text \n",
        "text5 = ['The workers at the industrial plant were overworked.', 'The plant was no longer bearing flowers.']\n",
        "\n",
        "# Anaylze the first sentence and print the definition of the word \"plant\"\n",
        "print( \"=============== analyse sentence 1 =================\\n\")\n",
        "print (\"Context-1:\", text5[0])  \n",
        "answer = simple_lesk(text5[0],'plant')  \n",
        "print (\"Sense:\", answer)  \n",
        "print (\"Definition : \", answer.definition())  \n",
        "\n",
        "# Anaylze the second sentence and print the definition of the word \"plant\"\n",
        "print( \"\\n\\n=============== analyse sentence 2 =================\\n\")\n",
        "print (\"Context-2:\", text5[1])  \n",
        "answer = simple_lesk(text5[1],'plant')  \n",
        "print (\"Sense:\", answer)  \n",
        "print (\"Definition : \", answer.definition())  "
      ],
      "metadata": {
        "id": "WrAM723hYImV",
        "outputId": "f7dfb052-6e9d-4fac-b780-ddb1d96c1027",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== analyse sentence 1 =================\n",
            "\n",
            "Context-1: The workers at the industrial plant were overworked.\n",
            "Sense: Synset('trust.v.01')\n",
            "Definition :  have confidence or faith in\n",
            "\n",
            "\n",
            "=============== analyse sentence 2 =================\n",
            "\n",
            "Context-2: The plant was no longer bearing flowers.\n",
            "Sense: Synset('bank.n.03')\n",
            "Definition :  a long ridge or pile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ambiguation of the word *fair*"
      ],
      "metadata": {
        "id": "d7T1C_OuYFKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample text \n",
        "text6 = ['Everyone needs to be given a fair chance in the competition.', 'The annual fair in our city is next weekend.']\n",
        "\n",
        "# Anaylze the first sentence and print the definition of the word \"fair\"\n",
        "print( \"=============== analyse sentence 1 =================\\n\")\n",
        "print (\"Context-1:\", text6[0])  \n",
        "answer = simple_lesk(text6[0],'fair')  \n",
        "print (\"Sense:\", answer)  \n",
        "print (\"Definition : \", answer.definition())  \n",
        "\n",
        "# Anaylze the second sentence and print the definition of the word \"fair\"\n",
        "print( \"\\n\\n=============== analyse sentence 2 =================\\n\")\n",
        "print (\"Context-2:\", text6[1])  \n",
        "answer = simple_lesk(text6[1],'fair')  \n",
        "print (\"Sense:\", answer)  \n",
        "print (\"Definition : \", answer.definition())  "
      ],
      "metadata": {
        "id": "WhjZ7MPJYJOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **References**\n",
        "\n",
        "- [1] NLP and Computer Vision_DLMAINLPCV01 Lecture Book\n",
        "- [2] https://www.nltk.org/api/nltk.html#nltk.wsd.lesk\n",
        "- [3] http://www.nltk.org/howto/wsd.html\n",
        "- [4] https://pypi.org/project/pywsd/\n",
        "- [5] https://pypi.org/project/wn/\n",
        "- [6] https://aclanthology.org/2021.gwc-1.12/\n"
      ],
      "metadata": {
        "id": "fPge5oRLQwid"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHARdTvlix3T"
      },
      "source": [
        "Copyright Â© 2022 IU International University of Applied Sciences"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "colab": {
      "name": "nlp_1-5_word_sense_disambiguation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgPmSJ95ix2q"
      },
      "source": [
        "# **Word Sense Disambiguation**\n",
        "\n",
        "Words can have different meanings in different contexts. Sometimes the intended\n",
        "meaning of a word is hard to understand and leads to miscommunication. How does\n",
        "NLP approach this challenge? If a word has multiple meanings, this is called word\n",
        "sense ambiguity. While solving syntactic ambiguity is done with part-of-speech (POS)\n",
        "tagging, solving semantic ambiguity is done with word sense disambiguation (WSD).\n",
        "The challenge is to semantically separate words by their meaning in context [[1]](#scrollTo=fPge5oRLQwid).\n",
        "\n",
        "This notebook shows some basic WSD examples by using the following techniques:\n",
        "* Natural Language Toolkit (NLTK)\n",
        "* Pywsd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Natural Language Toolkit (NLTK)**\n",
        "In this section the disambiguation of words with the **N**atural **L**anguage **T**ool**k**it (``NLTK``) is shown.<br>\n",
        "\n",
        "For more detail about word sense disambiguation NLTK please refer to [[2]](#scrollTo=fPge5oRLQwid)"
      ],
      "metadata": {
        "id": "4NVHzWOj-OpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import WordNet and Lesk\n",
        "\n",
        "WordNet® is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept. Synsets are interlinked by means of conceptual-semantic and lexical relations based on [[3]](#scrollTo=fPge5oRLQwid). \n",
        "\n",
        "The Lesk algorithm is an example of a knowledge-based method and is based on contextual overlap of dictionary definitions. The Lesk algorithm works as follows: We identify the overlapping definitions (underlined in this example) based on the contextual overlap among our Wiktionary definitions referring to the various senses of the ambiguous words. The approach is based on the assumption that words used together are also related to each other. For more detail about ``Lesk``, please refer to [[1]](#scrollTo=fPge5oRLQwid)"
      ],
      "metadata": {
        "id": "JH715v--MzGy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvXVxIxHjHa5",
        "outputId": "e3f5b6e8-dc33-4818-a55e-68f299fd8524"
      },
      "source": [
        "# Import nltk module\n",
        "# Download 'wordnet' package by using the nltk module\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOGMWCyFix3A"
      },
      "source": [
        "# Import lesk library\n",
        "# Import WordNet class by using the nltk.corpus package.\n",
        "## It is used to access the contents of a diverse set of corpora [4].\n",
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPZqdj4Cix3C"
      },
      "source": [
        "### Ambiguation of the word *bank*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfuYxpA3ix3E",
        "outputId": "ea671d8d-21e4-4c3a-96d9-fc7781ab913a"
      },
      "source": [
        "# Create sample sentences \n",
        "bank_sents = ['I went to the bank to deposit my money.',\n",
        "              'The river bank was full of dead fishes.']\n",
        "\n",
        "# By using lesk algorithm, anaylze the first sentence and print the definition of the word \"bank\"\n",
        "print( \"=============== analyse sentence 1 =================\\n\")\n",
        "print( \"Context:\", bank_sents[0])\n",
        "answer = lesk(bank_sents[0], 'bank') \n",
        "print( \"Sense:\", answer)\n",
        "print( \"Definition:\",answer.definition())\n",
        "\n",
        "# Anaylze the second sentence and print the definition of the word \"bank\"\n",
        "print( \"\\n=============== analyse sentence 2 =================\\n\")\n",
        "print( \"Context:\", bank_sents[1])\n",
        "answer = lesk(bank_sents[1].split(), 'bank', 'n')\n",
        "print( \"Sense:\", answer)\n",
        "print( \"Definition:\", answer.definition())\n",
        "\n",
        "# For a general overview, print all definitions of the word \"bank\"\n",
        "print( \"\\n=============== all definitions of \\'bank\\'===============\\n\")\n",
        "for s in wn.synsets('bank'):\n",
        "    print('\\t', s, s.definition())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== analyse sentence 1 =================\n",
            "\n",
            "Context: I went to the bank to deposit my money.\n",
            "Sense: Synset('savings_bank.n.02')\n",
            "Definition: a container (usually with a slot in the top) for keeping money at home\n",
            "\n",
            "=============== analyse sentence 2 =================\n",
            "\n",
            "Context: The river bank was full of dead fishes.\n",
            "Sense: Synset('bank.n.09')\n",
            "Definition: a building in which the business of banking transacted\n",
            "\n",
            "=============== all definitions of 'bank'===============\n",
            "\n",
            "\t Synset('bank.n.01') sloping land (especially the slope beside a body of water)\n",
            "\t Synset('depository_financial_institution.n.01') a financial institution that accepts deposits and channels the money into lending activities\n",
            "\t Synset('bank.n.03') a long ridge or pile\n",
            "\t Synset('bank.n.04') an arrangement of similar objects in a row or in tiers\n",
            "\t Synset('bank.n.05') a supply or stock held in reserve for future use (especially in emergencies)\n",
            "\t Synset('bank.n.06') the funds held by a gambling house or the dealer in some gambling games\n",
            "\t Synset('bank.n.07') a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
            "\t Synset('savings_bank.n.02') a container (usually with a slot in the top) for keeping money at home\n",
            "\t Synset('bank.n.09') a building in which the business of banking transacted\n",
            "\t Synset('bank.n.10') a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
            "\t Synset('bank.v.01') tip laterally\n",
            "\t Synset('bank.v.02') enclose with a bank\n",
            "\t Synset('bank.v.03') do business with a bank or keep an account at a bank\n",
            "\t Synset('bank.v.04') act as the banker in a game or in gambling\n",
            "\t Synset('bank.v.05') be in the banking business\n",
            "\t Synset('deposit.v.02') put into a bank account\n",
            "\t Synset('bank.v.07') cover with ashes so to control the rate of burning\n",
            "\t Synset('trust.v.01') have confidence or faith in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swQ-5k8vix3I"
      },
      "source": [
        "### Ambiguation of the word *plant*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9Nf5VAdix3K",
        "outputId": "407a8e91-7842-4197-aa43-2bbd1a58c983"
      },
      "source": [
        "# Create sample sentences\n",
        "plant_sents = ['The workers at the industrial plant were overworked.', 'The plant was no longer bearing flowers.']\n",
        "\n",
        "# By using lesk algorithm, anaylze the first sentence and print the definition of the word \"plant\"\n",
        "print( \"=============== analyse sentence 1 =================\\n\")\n",
        "print( \"Context:\", plant_sents[0])\n",
        "answer_1 = lesk(plant_sents[0].split(),'plant','n')\n",
        "print( \"Sense:\", answer_1)\n",
        "print( \"Definition:\",answer_1.definition())\n",
        "\n",
        "# Anaylze the second sentence and print the definition of the word \"plant\"\n",
        "print( \"\\n=============== analyse sentence 2 =================\\n\")\n",
        "print( \"Context:\", plant_sents[1])\n",
        "answer_2 = lesk(plant_sents[1],'plant','n')\n",
        "print( \"Sense:\", answer_2)\n",
        "print( \"Definition:\",answer_2.definition())\n",
        "\n",
        "# For a general overview, print all definitions of the word \"plant\"\n",
        "print( \"\\n=============== all definitions of \\'plant\\'===============\\n\")\n",
        "for s in wn.synsets('plant'):\n",
        "    print('\\t', s, s.definition())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== analyse sentence 1 =================\n",
            "\n",
            "Context: The workers at the industrial plant were overworked.\n",
            "Sense: Synset('plant.n.03')\n",
            "Definition: an actor situated in the audience whose acting is rehearsed but seems spontaneous to the audience\n",
            "\n",
            "=============== analyse sentence 2 =================\n",
            "\n",
            "Context: The plant was no longer bearing flowers.\n",
            "Sense: Synset('plant.n.02')\n",
            "Definition: (botany) a living organism lacking the power of locomotion\n",
            "\n",
            "=============== all definitions of 'plant'===============\n",
            "\n",
            "\t Synset('plant.n.01') buildings for carrying on industrial labor\n",
            "\t Synset('plant.n.02') (botany) a living organism lacking the power of locomotion\n",
            "\t Synset('plant.n.03') an actor situated in the audience whose acting is rehearsed but seems spontaneous to the audience\n",
            "\t Synset('plant.n.04') something planted secretly for discovery by another\n",
            "\t Synset('plant.v.01') put or set (seeds, seedlings, or plants) into the ground\n",
            "\t Synset('implant.v.01') fix or set securely or deeply\n",
            "\t Synset('establish.v.02') set up or lay the groundwork for\n",
            "\t Synset('plant.v.04') place into a river\n",
            "\t Synset('plant.v.05') place something or someone in a certain position in order to secretly observe or deceive\n",
            "\t Synset('plant.v.06') put firmly in the mind\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SLhhgQdix3M"
      },
      "source": [
        "### Ambiguation of the word *fair*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9zShRWZix3N",
        "outputId": "02f6d7df-2310-417e-8189-fbfcb9ebf08f"
      },
      "source": [
        "# Create sample sentences\n",
        "sntc_1 = \"Everyone needs to be given a fair chance in the competition.\"\n",
        "sntc_2 = \"The annual fair in our city is next weekend.\"\n",
        "\n",
        "# By using lesk algorithm, anaylze the first sentence and print the definition of the word \"fair\"\n",
        "print( \"=============== analyse sentence 1 =================\\n\")\n",
        "print( \"Context:\", sntc_1)\n",
        "answer_1 = lesk(sntc_1,'fair')\n",
        "print( \"Sense:\", answer_1)\n",
        "print( \"Definition:\",answer_1.definition())\n",
        "\n",
        "# Anaylze the second sentence and print the definition of the word \"fair\"\n",
        "print( \"\\n=============== analyse sentence 2 =================\\n\")\n",
        "print( \"Context:\", sntc_2)\n",
        "answer_2 = lesk(sntc_2,'fair', 'n')\n",
        "print( \"Sense:\", answer_2)\n",
        "print( \"Definition:\",answer_2.definition())\n",
        "\n",
        "# For a general overview, print all definitions of the word \"fair\"\n",
        "print( \"\\n=============== all definitions of \\'fair\\'===============\\n\")\n",
        "for s in wn.synsets('fair'):\n",
        "    print('\\t', s, s.definition())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== analyse sentence 1 =================\n",
            "\n",
            "Context: Everyone needs to be given a fair chance in the competition.\n",
            "Sense: Synset('fairly.r.02')\n",
            "Definition: without favoring one party, in a fair evenhanded manner\n",
            "\n",
            "=============== analyse sentence 2 =================\n",
            "\n",
            "Context: The annual fair in our city is next weekend.\n",
            "Sense: Synset('fair.n.03')\n",
            "Definition: a competitive exhibition of farm products\n",
            "\n",
            "=============== all definitions of 'fair'===============\n",
            "\n",
            "\t Synset('carnival.n.03') a traveling show; having sideshows and rides and games of skill etc.\n",
            "\t Synset('fair.n.02') gathering of producers to promote business\n",
            "\t Synset('fair.n.03') a competitive exhibition of farm products\n",
            "\t Synset('bazaar.n.03') a sale of miscellany; often for charity\n",
            "\t Synset('fair.v.01') join so that the external surfaces blend smoothly\n",
            "\t Synset('fair.a.01') free from favoritism or self-interest or bias or deception; conforming with established standards or rules\n",
            "\t Synset('fair.s.02') not excessive or extreme\n",
            "\t Synset('bonny.s.01') very pleasing to the eye\n",
            "\t Synset('fair.a.04') (of a baseball) hit between the foul lines\n",
            "\t Synset('average.s.03') lacking exceptional quality or ability\n",
            "\t Synset('fair.s.06') attractively feminine\n",
            "\t Synset('clean.s.11') (of a manuscript) having few alterations or corrections\n",
            "\t Synset('honest.s.07') gained or earned without cheating or stealing\n",
            "\t Synset('fair.s.09') free of clouds or rain\n",
            "\t Synset('fair.s.10') (used of hair or skin) pale or light-colored; \n",
            "\t Synset('fairly.r.03') in conformity with the rules or laws and without fraud or cheating\n",
            "\t Synset('fairly.r.02') without favoring one party, in a fair evenhanded manner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "xxxx"
      ],
      "metadata": {
        "id": "Q82q9dwK8R7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pywsd**\n",
        "Pywsd (Tan, 2014) is a Python library that provides WSD functions as well as several variations of the Lesk algorithm [[1]](#scrollTo=fPge5oRLQwid)."
      ],
      "metadata": {
        "id": "XnvDSfYy-YWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pywsd"
      ],
      "metadata": {
        "id": "4_feI89HA9Pg",
        "outputId": "c9c05d58-a399-4734-a0f4-ae35d4d8d689",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pywsd in /usr/local/lib/python3.7/dist-packages (1.2.4)\n",
            "Requirement already satisfied: wn in /usr/local/lib/python3.7/dist-packages (from pywsd) (0.9.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.15.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.3.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pywsd) (3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (4.64.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (2022.4.24)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2022.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (2.23.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (4.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (2021.10.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U wn==0.0.22"
      ],
      "metadata": {
        "id": "YmpRgxijC8oV",
        "outputId": "66817dc1-2941-463d-bd60-b1c7388e902c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wn==0.0.22\n",
            "  Downloading wn-0.0.22.tar.gz (31.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.5 MB 1.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wn\n",
            "  Building wheel for wn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wn: filename=wn-0.0.22-py3-none-any.whl size=31618484 sha256=95c1a4f58d5a908b1a0592b4f2d03b84c7c2d567e18b58690ef2bb7468378461\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/0d/59/4b7902879d8cbad9bb73aaf0cc0a051edc1b18da983889c412\n",
            "Successfully built wn\n",
            "Installing collected packages: wn\n",
            "  Attempting uninstall: wn\n",
            "    Found existing installation: wn 0.9.1\n",
            "    Uninstalling wn-0.9.1:\n",
            "      Successfully uninstalled wn-0.9.1\n",
            "Successfully installed wn-0.0.22\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "wn"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pywsd.lesk import simple_lesk "
      ],
      "metadata": {
        "id": "n2hi79CYBEi1",
        "outputId": "8a839a93-f6e4-42a0-aa7b-a378f7844c30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ebba752f4e17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpywsd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlesk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msimple_lesk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pywsd/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet_30_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'WordNet' from 'wn' (/usr/local/lib/python3.7/dist-packages/wn/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pywsd.lesk import simple_lesk\n",
        "sent = 'I went to the bank to deposit my money'\n",
        "ambiguous = 'bank'\n",
        "answer = simple_lesk(sent, ambiguous, pos='n')\n",
        "print (answer)\n",
        "print (answer.definition())\n"
      ],
      "metadata": {
        "id": "SY2wfCVUBZw2",
        "outputId": "b24f4b80-8dc0-4ff7-ae4d-69f9648e778a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-baacbb33b0ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpywsd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlesk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msimple_lesk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'I went to the bank to deposit my money'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mambiguous\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bank'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_lesk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pywsd/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet_30_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'WordNet' from 'wn' (/usr/local/lib/python3.7/dist-packages/wn/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **References**\n",
        "\n",
        "- [1] NLP and Computer Vision_DLMAINLPCV01 Lecture Book\n",
        "\n",
        "\n",
        "- [1] https://www.nltk.org/api/nltk.html#nltk.wsd.lesk\n",
        "- [2] http://www.nltk.org/howto/wsd.html\n",
        "- [3] https://wordnet.princeton.edu/\n",
        "- [4] https://www.nltk.org/howto/corpus.html\n",
        "\n"
      ],
      "metadata": {
        "id": "fPge5oRLQwid"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHARdTvlix3T"
      },
      "source": [
        "Copyright © 2022 IU International University of Applied Sciences"
      ]
    }
  ]
}
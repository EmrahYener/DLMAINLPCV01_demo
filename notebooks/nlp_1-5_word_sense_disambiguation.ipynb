{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "colab": {
      "name": "nlp_1-5_word_sense_disambiguation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgPmSJ95ix2q"
      },
      "source": [
        "# **Word Sense Disambiguation**\n",
        "\n",
        "Words can have different meanings in different contexts. Sometimes the intended\n",
        "meaning of a word is hard to understand and leads to miscommunication. If a word has multiple meanings, this is called word\n",
        "sense ambiguity. While solving syntactic ambiguity is done with part-of-speech (POS)\n",
        "tagging, solving semantic ambiguity is done with word sense disambiguation (WSD).\n",
        "The challenge is to semantically separate words by their meaning in context [[1]](#scrollTo=fPge5oRLQwid).\n",
        "\n",
        "This notebook shows some basic WSD examples by using the following libraries:\n",
        "* ``nltk``\n",
        "* ``pywsd``"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **``nltk``**\n",
        "``nltk``(Natural Language Toolkit) is an open source Python library for natural language processing. For more detail about ``nltk``, please refer to [[2]](https://www.nltk.org/api/nltk.html#nltk.wsd.lesk)."
      ],
      "metadata": {
        "id": "4NVHzWOj-OpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "h6i1YboyiOCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import ``wordnet``\n",
        "\n",
        "``wordnet`` is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept. Synsets are interlinked by means of conceptual-semantic and lexical relations [[3]](http://www.nltk.org/howto/wsd.html). "
      ],
      "metadata": {
        "id": "JH715v--MzGy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvXVxIxHjHa5",
        "outputId": "8c9ddc99-4bca-4736-f802-5e93aea5bf30"
      },
      "source": [
        "# Import nltk module\n",
        "import nltk\n",
        "\n",
        "# Download 'wordnet' package by using the nltk module\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Import WordNet class by using the nltk.corpus package\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import ``lesk``\n",
        "The ``lesk`` algorithm is an example of a knowledge-based method and is based on contextual overlap of dictionary definitions. It works as follows: We identify the overlapping definitions (underlined in this example) based on the contextual overlap among our Wiktionary definitions referring to the various senses of the ambiguous words. The approach is based on the assumption that words used together are also related to each other [[1]](#scrollTo=fPge5oRLQwid)."
      ],
      "metadata": {
        "id": "BM8WjVjGbzux"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOGMWCyFix3A"
      },
      "source": [
        "# Import lesk library\n",
        "from nltk.wsd import lesk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPZqdj4Cix3C"
      },
      "source": [
        "### Apply WSD for some words"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bank"
      ],
      "metadata": {
        "id": "q3p0_CqVioJz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfuYxpA3ix3E",
        "outputId": "a9cc9018-9392-4f5d-b84e-74f6313628ac"
      },
      "source": [
        "# Create sample text \n",
        "text1 = ['I went to the bank to deposit my money.',\n",
        "              'The river bank was full of dead fishes.']\n",
        "\n",
        "# By using lesk algorithm, anaylze the first sentence and print the definition of the word \"bank\"\n",
        "print( \"=============== analyse sentence 1 =================\\n\")\n",
        "print( \"Context:\", text1[0])\n",
        "answer1 = lesk(text1[0], 'bank') \n",
        "print( \"Sense:\", answer1)\n",
        "print( \"Definition:\",answer1.definition())\n",
        "\n",
        "# Anaylze the second sentence and print the definition of the word \"bank\"\n",
        "print( \"\\n\\n=============== analyse sentence 2 =================\\n\")\n",
        "print( \"Context:\", text1[1])\n",
        "answer2 = lesk(text1[1].split(), 'bank', 'n')\n",
        "print( \"Sense:\", answer2)\n",
        "print( \"Definition:\", answer2.definition())\n",
        "\n",
        "# For a general overview, print all definitions of the word \"bank\"\n",
        "print( \"\\n\\n=============== all definitions of \\'bank\\'===============\\n\")\n",
        "for s in wn.synsets('bank'):\n",
        "    print('\\t', s, s.definition())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== analyse sentence 1 =================\n",
            "\n",
            "Context: I went to the bank to deposit my money.\n",
            "Sense: Synset('savings_bank.n.02')\n",
            "Definition: a container (usually with a slot in the top) for keeping money at home\n",
            "\n",
            "\n",
            "=============== analyse sentence 2 =================\n",
            "\n",
            "Context: The river bank was full of dead fishes.\n",
            "Sense: Synset('bank.n.09')\n",
            "Definition: a building in which the business of banking transacted\n",
            "\n",
            "\n",
            "=============== all definitions of 'bank'===============\n",
            "\n",
            "\t Synset('bank.n.01') sloping land (especially the slope beside a body of water)\n",
            "\t Synset('depository_financial_institution.n.01') a financial institution that accepts deposits and channels the money into lending activities\n",
            "\t Synset('bank.n.03') a long ridge or pile\n",
            "\t Synset('bank.n.04') an arrangement of similar objects in a row or in tiers\n",
            "\t Synset('bank.n.05') a supply or stock held in reserve for future use (especially in emergencies)\n",
            "\t Synset('bank.n.06') the funds held by a gambling house or the dealer in some gambling games\n",
            "\t Synset('bank.n.07') a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
            "\t Synset('savings_bank.n.02') a container (usually with a slot in the top) for keeping money at home\n",
            "\t Synset('bank.n.09') a building in which the business of banking transacted\n",
            "\t Synset('bank.n.10') a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
            "\t Synset('bank.v.01') tip laterally\n",
            "\t Synset('bank.v.02') enclose with a bank\n",
            "\t Synset('bank.v.03') do business with a bank or keep an account at a bank\n",
            "\t Synset('bank.v.04') act as the banker in a game or in gambling\n",
            "\t Synset('bank.v.05') be in the banking business\n",
            "\t Synset('deposit.v.02') put into a bank account\n",
            "\t Synset('bank.v.07') cover with ashes so to control the rate of burning\n",
            "\t Synset('trust.v.01') have confidence or faith in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swQ-5k8vix3I"
      },
      "source": [
        "#### Plant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9Nf5VAdix3K",
        "outputId": "299bf94a-e50e-4a70-b1ed-6bb3cb849a66"
      },
      "source": [
        "# Create sample text\n",
        "text2 = ['The workers at the industrial plant were overworked.', 'The plant was no longer bearing flowers.']\n",
        "\n",
        "# By using lesk algorithm, anaylze the first sentence and print the definition of the word \"plant\"\n",
        "print( \"=============== analyse sentence 1 =================\\n\")\n",
        "print( \"Context:\", text2[0])\n",
        "answer1 = lesk(text2[0].split(),'plant','n')\n",
        "print( \"Sense:\", answer1)\n",
        "print( \"Definition:\",answer1.definition())\n",
        "\n",
        "# Anaylze the second sentence and print the definition of the word \"plant\"\n",
        "print( \"\\n\\n=============== analyse sentence 2 =================\\n\")\n",
        "print( \"Context:\", text2[1])\n",
        "answer2 = lesk(text2[1],'plant','n')\n",
        "print( \"Sense:\", answer2)\n",
        "print( \"Definition:\",answer2.definition())\n",
        "\n",
        "# For a general overview, print all definitions of the word \"plant\"\n",
        "print( \"\\n\\n=============== all definitions of \\'plant\\'===============\\n\")\n",
        "for s in wn.synsets('plant'):\n",
        "    print('\\t', s, s.definition())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== analyse sentence 1 =================\n",
            "\n",
            "Context: The workers at the industrial plant were overworked.\n",
            "Sense: Synset('plant.n.03')\n",
            "Definition: an actor situated in the audience whose acting is rehearsed but seems spontaneous to the audience\n",
            "\n",
            "\n",
            "=============== analyse sentence 2 =================\n",
            "\n",
            "Context: The plant was no longer bearing flowers.\n",
            "Sense: Synset('plant.n.02')\n",
            "Definition: (botany) a living organism lacking the power of locomotion\n",
            "\n",
            "\n",
            "=============== all definitions of 'plant'===============\n",
            "\n",
            "\t Synset('plant.n.01') buildings for carrying on industrial labor\n",
            "\t Synset('plant.n.02') (botany) a living organism lacking the power of locomotion\n",
            "\t Synset('plant.n.03') an actor situated in the audience whose acting is rehearsed but seems spontaneous to the audience\n",
            "\t Synset('plant.n.04') something planted secretly for discovery by another\n",
            "\t Synset('plant.v.01') put or set (seeds, seedlings, or plants) into the ground\n",
            "\t Synset('implant.v.01') fix or set securely or deeply\n",
            "\t Synset('establish.v.02') set up or lay the groundwork for\n",
            "\t Synset('plant.v.04') place into a river\n",
            "\t Synset('plant.v.05') place something or someone in a certain position in order to secretly observe or deceive\n",
            "\t Synset('plant.v.06') put firmly in the mind\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SLhhgQdix3M"
      },
      "source": [
        "#### Fair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9zShRWZix3N",
        "outputId": "a658b203-3895-48c6-a017-8800996f046a"
      },
      "source": [
        "# Create sample text\n",
        "text3 = ['Everyone needs to be given a fair chance in the competition.', 'The annual fair in our city is next weekend.']\n",
        "\n",
        "# By using lesk algorithm, anaylze the first sentence and print the definition of the word \"fair\"\n",
        "print( \"=============== analyse sentence 1 =================\\n\")\n",
        "print( \"Context:\", text3[0])\n",
        "answer1 = lesk(text3[0].split(),'fair','n')\n",
        "print( \"Sense:\", answer1)\n",
        "print( \"Definition:\",answer1.definition())\n",
        "\n",
        "# Anaylze the second sentence and print the definition of the word \"fair\"\n",
        "print( \"\\n\\n=============== analyse sentence 2 =================\\n\")\n",
        "print( \"Context:\", text3[1])\n",
        "answer2 = lesk(text3[1],'fair','n')\n",
        "print( \"Sense:\", answer2)\n",
        "print( \"Definition:\",answer2.definition())\n",
        "\n",
        "# For a general overview, print all definitions of the word \"fair\"\n",
        "print( \"\\n\\n=============== all definitions of \\'fair\\'===============\\n\")\n",
        "for s in wn.synsets('fair'):\n",
        "    print('\\t', s, s.definition())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== analyse sentence 1 =================\n",
            "\n",
            "Context: Everyone needs to be given a fair chance in the competition.\n",
            "Sense: Synset('fair.n.03')\n",
            "Definition: a competitive exhibition of farm products\n",
            "\n",
            "\n",
            "=============== analyse sentence 2 =================\n",
            "\n",
            "Context: The annual fair in our city is next weekend.\n",
            "Sense: Synset('fair.n.03')\n",
            "Definition: a competitive exhibition of farm products\n",
            "\n",
            "\n",
            "=============== all definitions of 'fair'===============\n",
            "\n",
            "\t Synset('carnival.n.03') a traveling show; having sideshows and rides and games of skill etc.\n",
            "\t Synset('fair.n.02') gathering of producers to promote business\n",
            "\t Synset('fair.n.03') a competitive exhibition of farm products\n",
            "\t Synset('bazaar.n.03') a sale of miscellany; often for charity\n",
            "\t Synset('fair.v.01') join so that the external surfaces blend smoothly\n",
            "\t Synset('fair.a.01') free from favoritism or self-interest or bias or deception; conforming with established standards or rules\n",
            "\t Synset('fair.s.02') not excessive or extreme\n",
            "\t Synset('bonny.s.01') very pleasing to the eye\n",
            "\t Synset('fair.a.04') (of a baseball) hit between the foul lines\n",
            "\t Synset('average.s.03') lacking exceptional quality or ability\n",
            "\t Synset('fair.s.06') attractively feminine\n",
            "\t Synset('clean.s.11') (of a manuscript) having few alterations or corrections\n",
            "\t Synset('honest.s.07') gained or earned without cheating or stealing\n",
            "\t Synset('fair.s.09') free of clouds or rain\n",
            "\t Synset('fair.s.10') (used of hair or skin) pale or light-colored; \n",
            "\t Synset('fairly.r.03') in conformity with the rules or laws and without fraud or cheating\n",
            "\t Synset('fairly.r.02') without favoring one party, in a fair evenhanded manner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **``pywsd``**\n",
        "``pywsd`` is a Python library that provides WSD functions as well as several variations of the Lesk algorithm [[1]](#scrollTo=fPge5oRLQwid).\n",
        "\n",
        "For more detail about ``pywsd``, please refer to [[4]](https://pypi.org/project/pywsd/)."
      ],
      "metadata": {
        "id": "XnvDSfYy-YWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "45TfUvkfi9QU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install Pywsd"
      ],
      "metadata": {
        "id": "_csm4xc0R-_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pywsd  "
      ],
      "metadata": {
        "id": "4_feI89HA9Pg",
        "outputId": "a42f6cf1-9dc7-4104-f6b5-fd59ab81b0a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pywsd\n",
            "  Downloading pywsd-1.2.4.tar.gz (26.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.8 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pywsd) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.3.5)\n",
            "Collecting wn\n",
            "  Downloading wn-0.9.1-py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2022.1)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (2.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (4.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (1.24.3)\n",
            "Building wheels for collected packages: pywsd\n",
            "  Building wheel for pywsd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pywsd: filename=pywsd-1.2.4-py3-none-any.whl size=26940436 sha256=e833ed6fc8f5eacbc2593128bcefb971428d43ae403fc7b24098478c4b1807ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/67/c0/6e6fa8456d1374b393328368316c3b33844cb4043bd225bc66\n",
            "Successfully built pywsd\n",
            "Installing collected packages: wn, pywsd\n",
            "Successfully installed pywsd-1.2.4 wn-0.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install ``wn``\n",
        "``wn`` is a new Python library for working with wordnets. Unlike previous libraries, ``wn`` is built from the beginning to accommodate multiple wordnets (for multiple languages or multiple versions of the same wordnet) while retaining the ability to query and traverse them independently. For more detail about the ``wn`` library, please refer to [[5]](https://pypi.org/project/wn/) and [[6]](https://aclanthology.org/2021.gwc-1.12/).\n",
        "\n"
      ],
      "metadata": {
        "id": "FpGN8eXeSFxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wn==0.0.22"
      ],
      "metadata": {
        "id": "YmpRgxijC8oV",
        "outputId": "ae6373e4-8723-4b98-d8c3-af7716b2e7b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wn==0.0.22\n",
            "  Downloading wn-0.0.22.tar.gz (31.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.5 MB 1.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wn\n",
            "  Building wheel for wn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wn: filename=wn-0.0.22-py3-none-any.whl size=31618484 sha256=1a21ed871c9266ec13dc810ed6f88051ba58e6063b31d97fd30e0c7ece5c2c8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/0d/59/4b7902879d8cbad9bb73aaf0cc0a051edc1b18da983889c412\n",
            "Successfully built wn\n",
            "Installing collected packages: wn\n",
            "  Attempting uninstall: wn\n",
            "    Found existing installation: wn 0.9.1\n",
            "    Uninstalling wn-0.9.1:\n",
            "      Successfully uninstalled wn-0.9.1\n",
            "Successfully installed wn-0.0.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import ``nltk``"
      ],
      "metadata": {
        "id": "GdGgQWKKUQok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "B4Hqv8tCMMf3",
        "outputId": "c8c2dfe9-130d-481e-c572-515677db7100",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import ``simple_lesk``"
      ],
      "metadata": {
        "id": "FHkuushxUcNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simple_lesk returns the sense most suited to the given word as per the Simple LESK Algorithm\n",
        "from pywsd.lesk import simple_lesk  "
      ],
      "metadata": {
        "id": "n2hi79CYBEi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61c0d85-b311-4971-f511-b24b88a01409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warming up PyWSD (takes ~10 secs)... took 3.9495387077331543 secs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply WSD for some words"
      ],
      "metadata": {
        "id": "7HwviBLLjCIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bank"
      ],
      "metadata": {
        "id": "G2gPMfkNWI8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample text \n",
        "text1 = ['I went to the bank to deposit my money', 'The river bank was full of dead fishes']\n",
        "\n",
        "# Anaylze the first sentence and print the definition of the word \"bank\"\n",
        "print( \"=============== analyse sentence 1 =================\\n\")\n",
        "print (\"Context-1:\", text1[0])  \n",
        "answer1 = simple_lesk(text1[0],'bank')  \n",
        "print (\"Sense:\", answer1)  \n",
        "print (\"Definition : \", answer1.definition())  \n",
        "\n",
        "# Anaylze the second sentence and print the definition of the word \"bank\"\n",
        "print( \"\\n\\n=============== analyse sentence 2 =================\\n\")\n",
        "print (\"Context-2:\", text1[1])  \n",
        "answer2 = simple_lesk(text1[1],'bank')  \n",
        "print (\"Sense:\", answer2)  \n",
        "print (\"Definition : \", answer2.definition())  \n",
        "\n",
        "#for s in wn.synsets('fair'):\n",
        "#    print('\\t', s, s.definition())"
      ],
      "metadata": {
        "id": "IW471hbAMjJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf2de3b4-ddf2-403a-ac7e-558c98ec3356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== analyse sentence 1 =================\n",
            "\n",
            "Context-1: I went to the bank to deposit my money\n",
            "Sense: Synset('depository_financial_institution.n.01')\n",
            "Definition :  a financial institution that accepts deposits and channels the money into lending activities\n",
            "\n",
            "\n",
            "=============== analyse sentence 2 =================\n",
            "\n",
            "Context-2: The river bank was full of dead fishes\n",
            "Sense: Synset('bank.n.01')\n",
            "Definition :  sloping land (especially the slope beside a body of water)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plant"
      ],
      "metadata": {
        "id": "6AD2Aw6uYB1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample text \n",
        "text2 = ['The workers at the industrial plant were overworked.', 'The plant was no longer bearing flowers.']\n",
        "\n",
        "# Anaylze the first sentence and print the definition of the word \"plant\"\n",
        "print( \"=============== analyse sentence 1 =================\\n\")\n",
        "print (\"Context-1:\", text2[0])  \n",
        "answer1 = simple_lesk(text2[0],'plant')  \n",
        "print (\"Sense:\", answer1)  \n",
        "print (\"Definition : \", answer1.definition())  \n",
        "\n",
        "# Anaylze the second sentence and print the definition of the word \"plant\"\n",
        "print( \"\\n\\n=============== analyse sentence 2 =================\\n\")\n",
        "print (\"Context-2:\", text2[1])  \n",
        "answer2 = simple_lesk(text2[1],'plant')  \n",
        "print (\"Sense:\", answer2)  \n",
        "print (\"Definition : \", answer2.definition())  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrAM723hYImV",
        "outputId": "481e4d82-03e9-4e2f-b1b4-7a46edd80114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== analyse sentence 1 =================\n",
            "\n",
            "Context-1: The workers at the industrial plant were overworked.\n",
            "Sense: Synset('plant.n.01')\n",
            "Definition :  buildings for carrying on industrial labor\n",
            "\n",
            "\n",
            "=============== analyse sentence 2 =================\n",
            "\n",
            "Context-2: The plant was no longer bearing flowers.\n",
            "Sense: Synset('plant.v.01')\n",
            "Definition :  put or set (seeds, seedlings, or plants) into the ground\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fair"
      ],
      "metadata": {
        "id": "d7T1C_OuYFKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample text \n",
        "text3 = ['Everyone needs to be given a fair chance in the competition.', 'The annual fair in our city is next weekend.']\n",
        "\n",
        "# Anaylze the first sentence and print the definition of the word \"fair\"\n",
        "print( \"=============== analyse sentence 1 =================\\n\")\n",
        "print (\"Context-1:\", text3[0])  \n",
        "answer1 = simple_lesk(text3[0],'fair')  \n",
        "print (\"Sense:\", answer1)  \n",
        "print (\"Definition : \", answer1.definition())  \n",
        "\n",
        "# Anaylze the second sentence and print the definition of the word \"fair\"\n",
        "print( \"\\n\\n=============== analyse sentence 2 =================\\n\")\n",
        "print (\"Context-2:\", text3[1])  \n",
        "answer2 = simple_lesk(text3[1],'fair')  \n",
        "print (\"Sense:\", answer2)  \n",
        "print (\"Definition : \", answer2.definition())  "
      ],
      "metadata": {
        "id": "WhjZ7MPJYJOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad81a378-0c6e-4465-d360-63f0cffeb3ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== analyse sentence 1 =================\n",
            "\n",
            "Context-1: Everyone needs to be given a fair chance in the competition.\n",
            "Sense: Synset('honest.s.07')\n",
            "Definition :  gained or earned without cheating or stealing\n",
            "\n",
            "\n",
            "=============== analyse sentence 2 =================\n",
            "\n",
            "Context-2: The annual fair in our city is next weekend.\n",
            "Sense: Synset('honest.s.07')\n",
            "Definition :  gained or earned without cheating or stealing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **References**\n",
        "\n",
        "- [1] NLP and Computer Vision_DLMAINLPCV01 Lecture Book\n",
        "- [2] https://www.nltk.org/api/nltk.html#nltk.wsd.lesk\n",
        "- [3] http://www.nltk.org/howto/wsd.html\n",
        "- [4] https://pypi.org/project/pywsd/\n",
        "- [5] https://pypi.org/project/wn/\n",
        "- [6] https://aclanthology.org/2021.gwc-1.12/\n"
      ],
      "metadata": {
        "id": "fPge5oRLQwid"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHARdTvlix3T"
      },
      "source": [
        "Copyright © 2022 IU International University of Applied Sciences"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "colab": {
      "name": "nlp_2-1_text_summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LGamZ8S_zyb"
      },
      "source": [
        "# **Text-Summarization**\n",
        "\n",
        "Text summarization in NLP describes methods to automatically generate text summaries containing the most relevant information from source texts. With text summarization, we use extractive and abstractive techniques. In extractive techniques, algorithms extract the most important word sequences of the document to produce a summary of the given text. Abstractive techniques generate summaries by generating a new text and paraphrase the content of the original document, pretty much like humans do when they write an abstract. In this section, we focus on extractive techniques. [[1]](#scrollTo=8Pzkt1Z_M6OH).\n",
        "\n",
        "\n",
        "This notebook shows examples for unsupervised text summerization with TextRank.\n",
        "\n",
        "A common unsupervised extractive summarization technique is TextRank. TextRank compares every sentence in the text with every other sentence by calculating a similarity score, for example, the cosine similarity for each sentence pair. The closer the score is to 1, the more similar the sentence is to the other sentence representing the other sentences in a good way. These scores are summed up for each sentence to get a rank. The higher the rank, the more important the sentence is in the text. Finally, the sentences can be sorted by rank and a summary can be built from a defined number of highest ranked sentences. TextRank is inspired by PageRank, an algorithm developed by Google that is used to rank web pages by their importance.\n",
        "\n",
        "\n",
        "Text summarizer can give a short summary of a large text. <br>\n",
        "[SpaCy](www.spacy.io) together with [pyTextRank](https://github.com/DerwenAI/pytextrank) have a text summarization model which is presented in this notebook.\n",
        "\n",
        "The following example is based on code-snippet for pytextrank: [derwin.ai](https://derwen.ai/docs/ptr/explain_summ/)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load resources"
      ],
      "metadata": {
        "id": "quUw02FBIAYz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xavxSpS-f3CI"
      },
      "source": [
        "### Install PyTextRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQIo1p4uAC8C"
      },
      "source": [
        "# Install PyTextRank \n",
        "## PyTextRank is a Python implementation of TextRank as a spaCy pipeline extension.\n",
        "!pip install pytextrank==3.0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load language model\n",
        "We will download \"en_core_web_sm\" English language model by using spaCy library.\n",
        "It is a small English pipeline trained on written web text (blogs, news, comments), that includes vocabulary, syntax and entities [[4]](https://spacy.io/models).\n",
        "It is optimized for CPU and its components are: tok2vec, tagger, parser, senter, ner, attribute_ruler, lemmatizer [[5]](https://spacy.io/models/en)."
      ],
      "metadata": {
        "id": "ibonn_5oG5BP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhdAZJnug3T8"
      },
      "source": [
        "# Download \"en_core_web_sm\" English language model\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HsF9N9igEwQ"
      },
      "source": [
        "### Import libraries and warnings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcW1TC8xrynl"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa3QK56i_zyx"
      },
      "source": [
        "# Import spaCy and pytextrank libraries\n",
        "import spacy\n",
        "import pytextrank\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "sp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare pipeline"
      ],
      "metadata": {
        "id": "fz8gz5rWIMDw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upP_NK5B_zy1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "025596b7-8e45-4790-bede-49470c613d08"
      },
      "source": [
        "# prepare pipeline\n",
        "sp.add_pipe('textrank', last=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pytextrank.base.BaseTextRank at 0x7f52462466d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijhBuc6be9bz"
      },
      "source": [
        "#### Basic Text-Summarization example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKOHaC9Me80Z"
      },
      "source": [
        "# Create sample text as SpaCy instance\n",
        "doc = sp(\n",
        "    \"Mr. and Mrs. Dursley, of number four, Private Drive, were proud to say \\\n",
        "they were perfectly normal, thank you very much. They were the last people you'd expect \\\n",
        "to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOffQTR7od4X",
        "outputId": "b2852e9a-1969-4370-8b41-26a4639d477c"
      },
      "source": [
        "# Print the noun chunks of the sample text\n",
        "for chunks in doc.noun_chunks:\n",
        "  print(chunks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mr. and Mrs. Dursley\n",
            "number\n",
            "Private Drive\n",
            "they\n",
            "you\n",
            "They\n",
            "the last people\n",
            "you\n",
            "anything\n",
            "they\n",
            "such nonsense\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSRfycdlpBjg",
        "outputId": "f499ba22-b8af-4351-f0b3-3d04e4b0e2a0"
      },
      "source": [
        "# Print entities of the document\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_, ent.start, ent.end)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dursley PERSON 3 4\n",
            "number four CARDINAL 6 8\n",
            "Private Drive FAC 9 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwC3SusLqI3Y",
        "outputId": "839b9eaa-788c-41bb-fd93-18a1bcf893e1"
      },
      "source": [
        "# Show top rated phrases\n",
        "\n",
        "# Iterate through each sentence in the doc, constructing a\n",
        "# [*lemma graph*](https://derwen.ai/docs/ptr/glossary/#lemma-graph),\n",
        "# then returning the top-ranked phrases.\n",
        "\n",
        "for p in doc._.phrases:\n",
        "    print(\"{:.4f} {:5d}  {}\".format(p.rank, p.count, p.text))\n",
        "    print(p.chunks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2058     1  such nonsense\n",
            "[such nonsense]\n",
            "0.1477     2  Private Drive\n",
            "[Private Drive, Private Drive]\n",
            "0.1000     1  number\n",
            "[number]\n",
            "0.0883     1  Dursley\n",
            "[Dursley]\n",
            "0.0697     1  Mr. and Mrs. Dursley\n",
            "[Mr. and Mrs. Dursley]\n",
            "0.0520     1  the last people\n",
            "[the last people]\n",
            "0.0462     1  number four\n",
            "[number four]\n",
            "0.0000     1  They\n",
            "[They]\n",
            "0.0000     1  anything\n",
            "[anything]\n",
            "0.0000     2  they\n",
            "[they, they]\n",
            "0.0000     2  you\n",
            "[you, you]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVUNK5qQqORa",
        "outputId": "562439d7-d576-4c56-f388-423e619f63a7"
      },
      "source": [
        "# Construct a list of the sentence boundaries with a phrase-vector (initialized to empty set) for each sentence.\n",
        "sent_bounds = [ [s.start, s.end, set([])] for s in doc.sents ]\n",
        "print(sent_bounds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 26, set()], [26, 53, set()]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1EI-aHeqUNu",
        "outputId": "41953ef1-145b-4a9e-99e1-9d149ee21e8b"
      },
      "source": [
        "# Iterate through the top-ranked phrases and add them to the \n",
        "# phrase-vector for each sentence.\n",
        "\n",
        "limit_phrases = 4\n",
        "\n",
        "phrase_id = 0\n",
        "unit_vector = []\n",
        "\n",
        "for p in doc._.phrases:\n",
        "    print(phrase_id, p.text, p.rank)\n",
        "\n",
        "    unit_vector.append(p.rank)\n",
        "\n",
        "    for chunk in p.chunks:\n",
        "        #print(\" \", chunk.start, chunk.end)\n",
        "\n",
        "        for sent_start, sent_end, sent_vector in sent_bounds:\n",
        "            if chunk.start >= sent_start and chunk.end <= sent_end:\n",
        "                #print(\" \", sent_start, chunk.start, chunk.end, sent_end)\n",
        "                sent_vector.add(phrase_id)\n",
        "                break\n",
        "\n",
        "    phrase_id += 1\n",
        "\n",
        "    if phrase_id == limit_phrases:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 such nonsense 0.20578727368601007\n",
            "1 Private Drive 0.1476932514643156\n",
            "2 number 0.10003737208485038\n",
            "3 Dursley 0.08830619471948406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-2d6_Yuqitq",
        "outputId": "8582bdd9-3b8f-4bf6-bd35-e0a76c29fc66"
      },
      "source": [
        "# Show the results\n",
        "\n",
        "# Look at the sentence boundaries with its phrase-vector\n",
        "print(sent_bounds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 26, {1, 2, 3}], [26, 53, {0}]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfN0utbbq5By",
        "outputId": "eb7e75b5-8938-4974-be91-400e66ad590a"
      },
      "source": [
        "# We also construct a unit_vector for all of the phrases, up to the limit requested.\n",
        "print(unit_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.20578727368601007, 0.1476932514643156, 0.10003737208485038, 0.08830619471948406]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WZJJnUBq6XH",
        "outputId": "f471f932-8719-47ff-9805-fbfd64b058d4"
      },
      "source": [
        "# Nomralize the unit_vector\n",
        "sum_ranks = sum(unit_vector)\n",
        "unit_vector = [ rank/sum_ranks for rank in unit_vector ]\n",
        "\n",
        "unit_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37980458370468767,\n",
              " 0.2725852424381945,\n",
              " 0.18463071976729584,\n",
              " 0.1629794540898221]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-a65t24q_cP",
        "outputId": "730b2c9e-e427-42d2-fc7d-7875629e18de"
      },
      "source": [
        "# Iterate through each sentence, calculating its euclidean distance from the unit vector.\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "sent_rank = {}\n",
        "sent_id = 0\n",
        "\n",
        "for sent_start, sent_end, sent_vector in sent_bounds:\n",
        "    #print(sent_vector)\n",
        "    sum_sq = 0.0\n",
        "\n",
        "    for phrase_id in range(len(unit_vector)):\n",
        "        #print(phrase_id, unit_vector[phrase_id])\n",
        "\n",
        "        if phrase_id not in sent_vector:\n",
        "            sum_sq += unit_vector[phrase_id]**2.0\n",
        "\n",
        "    sent_rank[sent_id] = sqrt(sum_sq)\n",
        "    sent_id += 1\n",
        "\n",
        "print(sent_rank)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 0.37980458370468767, 1: 0.3673602040672008}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du23UfWMrGE5",
        "outputId": "5de5cafc-32f9-43e9-fd9d-1791728724e8"
      },
      "source": [
        "# Sort the sentence indexes in descending order\n",
        "from operator import itemgetter\n",
        "\n",
        "sorted(sent_rank.items(), key=itemgetter(1)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 0.3673602040672008), (0, 0.37980458370468767)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tZyjO0krJbk",
        "outputId": "a7632a14-015a-407e-e124-0c51b063b331"
      },
      "source": [
        "# Extract the sentences with the lowest distance, up to the limit requested.\n",
        "limit_sentences = 2\n",
        "\n",
        "sent_text = {}\n",
        "sent_id = 0\n",
        "\n",
        "for sent in doc.sents:\n",
        "    sent_text[sent_id] = sent.text\n",
        "    sent_id += 1\n",
        "\n",
        "num_sent = 0\n",
        "\n",
        "for sent_id, rank in sorted(sent_rank.items(), key=itemgetter(1)):\n",
        "    print(sent_id, sent_text[sent_id])\n",
        "    num_sent += 1\n",
        "\n",
        "    if num_sent == limit_sentences:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\n",
            "0 Mr. and Mrs. Dursley, of number four, Private Drive, were proud to say they were perfectly normal, thank you very much.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **References**\n",
        "\n",
        "- [1] NLP and Computer Vision_DLMAINLPCV01 Course Book\n",
        "- [2] https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html\n",
        "\n",
        "https://www.kaggle.com/code/aggarwalrahul/nlp-text-summarization-using-textrank\n",
        "\n",
        "https://colab.research.google.com/github/prateekjoshi565/textrank_text_summarization/blob/master/TestRank_Text_Summarization.ipynb#scrollTo=jwxtPBlgO_Gk\n",
        "\n",
        "dataset: https://www.kaggle.com/code/emrahyener/nlp-text-summarization-using-textrank/edit"
      ],
      "metadata": {
        "id": "8Pzkt1Z_M6OH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2oMgGVZAivX"
      },
      "source": [
        "Copyright Â© 2022 IU International University of Applied Sciences"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "colab": {
      "name": "nlp_2-1_text_summarizaion_spaCy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LGamZ8S_zyb"
      },
      "source": [
        "# **Text summarization**\n",
        "\n",
        "Text summarizer can give a short summary of a large text. <br>\n",
        "[SpaCy](www.spacy.io) together with [pyTextRank](https://github.com/DerwenAI/pytextrank) have a text summriziation model which is presented in this notebook.\n",
        "\n",
        "the following example is based on that code-snippet for pytextrank: [derwin.ai](https://derwen.ai/docs/ptr/explain_summ/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xavxSpS-f3CI"
      },
      "source": [
        "#### install additional libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQIo1p4uAC8C"
      },
      "source": [
        "!pip install pytextrank==3.0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhdAZJnug3T8"
      },
      "source": [
        "# download language model for spacy\r\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HsF9N9igEwQ"
      },
      "source": [
        "#### load resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcW1TC8xrynl"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa3QK56i_zyx"
      },
      "source": [
        "# resources\n",
        "#\n",
        "import spacy\n",
        "import pytextrank\n",
        "import wikipedia\n",
        "#\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "#\n",
        "# core-model with German language:\n",
        "#sp = spacy.load('de_core_news_sm')\n",
        "#"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upP_NK5B_zy1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eacf6903-2460-4758-ebcc-ade8e8bedb64"
      },
      "source": [
        "# prepare pipeline\n",
        "#\n",
        "sp.add_pipe('textrank', last=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pytextrank.base.BaseTextRank at 0x7f55ae84e9d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijhBuc6be9bz"
      },
      "source": [
        "#### basic example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKOHaC9Me80Z"
      },
      "source": [
        "# create sample text\r\n",
        "#\r\n",
        "doc = sp(\r\n",
        "    \"Mr. and Mrs. Dursley, of number four, Private Drive, were proud to say \\\r\n",
        "    that they were perfectly normal, thank you very much. They were the last people you'd expect \\\r\n",
        "    to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\"\r\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOffQTR7od4X",
        "outputId": "541b6823-f768-490d-b6ed-2aaf20057e86"
      },
      "source": [
        "# extract the noun chunks of hte sample text\r\n",
        "#\r\n",
        "for chunks in doc.noun_chunks:\r\n",
        "  print(chunks)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mr. and Mrs. Dursley\n",
            "number\n",
            "Private Drive\n",
            "they\n",
            "you\n",
            "They\n",
            "the last people\n",
            "you\n",
            "anything\n",
            "they\n",
            "such nonsense\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSRfycdlpBjg",
        "outputId": "8d4c68f6-4090-4678-ede8-4e586e7af2bc"
      },
      "source": [
        "# extract entities\r\n",
        "#\r\n",
        "for ent in doc.ents:\r\n",
        "    print(ent.text, ent.label_, ent.start, ent.end)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dursley PERSON 3 4\n",
            "number four CARDINAL 6 8\n",
            "Private Drive FAC 9 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwC3SusLqI3Y",
        "outputId": "b2a87775-6cd7-4939-9d7d-1cd67d3fab9f"
      },
      "source": [
        "# show top rated phrases\r\n",
        "#\r\n",
        "# Iterate through each sentence in the doc, constructing a\r\n",
        "# [*lemma graph*](https://derwen.ai/docs/ptr/glossary/#lemma-graph)\r\n",
        "# then returning the top-ranked phrases.\r\n",
        "#\r\n",
        "for p in doc._.phrases:\r\n",
        "    print(\"{:.4f} {:5d}  {}\".format(p.rank, p.count, p.text))\r\n",
        "    print(p.chunks)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2058     1  such nonsense\n",
            "[such nonsense]\n",
            "0.1477     2  Private Drive\n",
            "[Private Drive, Private Drive]\n",
            "0.1000     1  number\n",
            "[number]\n",
            "0.0883     1  Dursley\n",
            "[Dursley]\n",
            "0.0697     1  Mr. and Mrs. Dursley\n",
            "[Mr. and Mrs. Dursley]\n",
            "0.0520     1  the last people\n",
            "[the last people]\n",
            "0.0462     1  number four\n",
            "[number four]\n",
            "0.0000     1  They\n",
            "[They]\n",
            "0.0000     1  anything\n",
            "[anything]\n",
            "0.0000     2  they\n",
            "[they, they]\n",
            "0.0000     2  you\n",
            "[you, you]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVUNK5qQqORa",
        "outputId": "6e1f6562-ceb4-4422-f871-6fde956c7cb1"
      },
      "source": [
        "# Construct a list of the sentence boundaries with a phrase vector (initialized to empty set) for each sentence.\r\n",
        "#\r\n",
        "sent_bounds = [ [s.start, s.end, set([])] for s in doc.sents ]\r\n",
        "sent_bounds"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 28, set()], [28, 56, set()]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1EI-aHeqUNu",
        "outputId": "5f488e0c-c898-4e94-95b3-db37aaf837cf"
      },
      "source": [
        "# Iterate through the top-ranked phrases, \r\n",
        "# added them to the phrase vector for each sentence.\r\n",
        "#\r\n",
        "limit_phrases = 4\r\n",
        "\r\n",
        "phrase_id = 0\r\n",
        "unit_vector = []\r\n",
        "\r\n",
        "for p in doc._.phrases:\r\n",
        "    print(phrase_id, p.text, p.rank)\r\n",
        "\r\n",
        "    unit_vector.append(p.rank)\r\n",
        "\r\n",
        "    for chunk in p.chunks:\r\n",
        "        print(\" \", chunk.start, chunk.end)\r\n",
        "\r\n",
        "        for sent_start, sent_end, sent_vector in sent_bounds:\r\n",
        "            if chunk.start >= sent_start and chunk.end <= sent_end:\r\n",
        "                print(\" \", sent_start, chunk.start, chunk.end, sent_end)\r\n",
        "                sent_vector.add(phrase_id)\r\n",
        "                break\r\n",
        "\r\n",
        "    phrase_id += 1\r\n",
        "\r\n",
        "    if phrase_id == limit_phrases:\r\n",
        "        break"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 such nonsense 0.20578727368601007\n",
            "  53 55\n",
            "  28 53 55 56\n",
            "1 Private Drive 0.1476932514643156\n",
            "  9 11\n",
            "  0 9 11 28\n",
            "  9 11\n",
            "  0 9 11 28\n",
            "2 number 0.10003737208485038\n",
            "  6 7\n",
            "  0 6 7 28\n",
            "3 Dursley 0.08830619471948406\n",
            "  3 4\n",
            "  0 3 4 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-2d6_Yuqitq",
        "outputId": "23f36f20-9d13-4723-9c9f-ea40ab233107"
      },
      "source": [
        "# display the results\r\n",
        "#\r\n",
        "sent_bounds"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 28, {1, 2, 3}], [28, 56, {0}]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3VVb2Jsqwxj",
        "outputId": "25ddd764-0879-4064-90b6-5c0b9938fa6d"
      },
      "source": [
        "for sent in doc.sents:\r\n",
        "    print(sent)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mr. and Mrs. Dursley, of number four, Private Drive, were proud to say     that they were perfectly normal, thank you very much.\n",
            "They were the last people you'd expect     to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfN0utbbq5By",
        "outputId": "5e7395c7-5c3b-4adc-e414-09950357b655"
      },
      "source": [
        "# We also construct a unit_vector for all of the phrases, up to the limit requested.\r\n",
        "#\r\n",
        "unit_vector"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20578727368601007,\n",
              " 0.1476932514643156,\n",
              " 0.10003737208485038,\n",
              " 0.08830619471948406]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WZJJnUBq6XH",
        "outputId": "a84e584f-1b57-47ab-a7bc-09d36ad66c22"
      },
      "source": [
        "sum_ranks = sum(unit_vector)\r\n",
        "unit_vector = [ rank/sum_ranks for rank in unit_vector ]\r\n",
        "\r\n",
        "unit_vector"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37980458370468767,\n",
              " 0.2725852424381945,\n",
              " 0.18463071976729584,\n",
              " 0.1629794540898221]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-a65t24q_cP",
        "outputId": "20a8b9d1-ff12-4852-fb83-9760516151f9"
      },
      "source": [
        "# Iterate through each sentence, calculating its euclidean distance from the unit vector.\r\n",
        "#\r\n",
        "from math import sqrt\r\n",
        "\r\n",
        "sent_rank = {}\r\n",
        "sent_id = 0\r\n",
        "\r\n",
        "for sent_start, sent_end, sent_vector in sent_bounds:\r\n",
        "    print(sent_vector)\r\n",
        "    sum_sq = 0.0\r\n",
        "\r\n",
        "    for phrase_id in range(len(unit_vector)):\r\n",
        "        print(phrase_id, unit_vector[phrase_id])\r\n",
        "\r\n",
        "        if phrase_id not in sent_vector:\r\n",
        "            sum_sq += unit_vector[phrase_id]**2.0\r\n",
        "\r\n",
        "    sent_rank[sent_id] = sqrt(sum_sq)\r\n",
        "    sent_id += 1\r\n",
        "\r\n",
        "print(sent_rank)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1, 2, 3}\n",
            "0 0.37980458370468767\n",
            "1 0.2725852424381945\n",
            "2 0.18463071976729584\n",
            "3 0.1629794540898221\n",
            "{0}\n",
            "0 0.37980458370468767\n",
            "1 0.2725852424381945\n",
            "2 0.18463071976729584\n",
            "3 0.1629794540898221\n",
            "{0: 0.37980458370468767, 1: 0.3673602040672008}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du23UfWMrGE5",
        "outputId": "62a65a1d-21ee-4db8-f377-90ec777df552"
      },
      "source": [
        "# Sort the sentence indexes in descending order\r\n",
        "#\r\n",
        "from operator import itemgetter\r\n",
        "\r\n",
        "sorted(sent_rank.items(), key=itemgetter(1)) "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 0.3673602040672008), (0, 0.37980458370468767)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tZyjO0krJbk",
        "outputId": "c619823f-630a-4b07-a33f-f3028bce5f26"
      },
      "source": [
        "# Extract the sentences with the lowest distance, up to the limit requested.\r\n",
        "#\r\n",
        "limit_sentences = 2\r\n",
        "\r\n",
        "sent_text = {}\r\n",
        "sent_id = 0\r\n",
        "\r\n",
        "for sent in doc.sents:\r\n",
        "    sent_text[sent_id] = sent.text\r\n",
        "    sent_id += 1\r\n",
        "\r\n",
        "num_sent = 0\r\n",
        "\r\n",
        "for sent_id, rank in sorted(sent_rank.items(), key=itemgetter(1)):\r\n",
        "    print(sent_id, sent_text[sent_id])\r\n",
        "    num_sent += 1\r\n",
        "\r\n",
        "    if num_sent == limit_sentences:\r\n",
        "        break"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 They were the last people you'd expect     to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\n",
            "0 Mr. and Mrs. Dursley, of number four, Private Drive, were proud to say     that they were perfectly normal, thank you very much.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2oMgGVZAivX"
      },
      "source": [
        "Copyright © 2021 IUBH Internationale Hochschule"
      ]
    }
  ]
}

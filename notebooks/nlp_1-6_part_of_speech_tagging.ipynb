{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "colab": {
      "name": "nlp_1-6_part_of_speech_tagging.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_X42HQ1pF84"
      },
      "source": [
        "# **Part-of-Speech Tagging**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1- Introduction**\n",
        "In this section, we demonstrate how to implement part-of-speech (POS)\n",
        "tagging.\n",
        "\n",
        "POS tagging is used to solve syntactic ambiguity. It adds grammatical word functions and categories to a\n",
        "given text [[1]](#scrollTo=op-j6UywUt5i). \n",
        "\n",
        "In the sentence “Our dogs bark all day,” the word “bark” appears as a verb\n",
        "(word category) taking the function of the predicate (word function). \n",
        "\n",
        "In “The bark of the\n",
        "old oak tree was wet,” the word “bark” is a noun (word category) in the function of the\n",
        "subject (word function). This example illustrates that context plays an important role in\n",
        "POS tagging [[1]](#scrollTo=op-j6UywUt5i).\n",
        "\n",
        "\n",
        "### **Content**\n",
        "In this notebook some basic examples for the following topic will be shown:\n",
        "* Part-Of-Speech (POS) tagging by using spaCy\n"
      ],
      "metadata": {
        "id": "p07VlvadPlrX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyo5PWLBpF9s"
      },
      "source": [
        "## **2- Part-Of-Speech (POS) tagging by using spaCy.**\n",
        "\n",
        "SpaCy is one of the most famous framework for NLP. It can be used for the implementation of tasks for sentiment analysis, chatbots, text summarization, intent and entity extraction, and others [[1]](#scrollTo=op-j6UywUt5i).\n",
        "\n",
        "More information about spaCy please refer to [[2]](#scrollTo=op-j6UywUt5i).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Code Examples**\n",
        "\n",
        "For POS tagging, we will follow the following steps:\n",
        "* Import the spaCy library\n",
        "* Load the language model (English)\n",
        "* Create a spaCy document\n",
        "* Access the POS tags by iterating over the document object\n",
        "* Print the POS tags"
      ],
      "metadata": {
        "id": "0JfXUPmkcWUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.** Import spaCy library and English load language model"
      ],
      "metadata": {
        "id": "O5kowC_hc37V"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rVtW6JEpF9f"
      },
      "source": [
        "# Import spaCy library to process the text\n",
        "## spaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python.\n",
        "## spaCy is designed specifically for production use and helps you build applications that process and “understand” large volumes of text. \n",
        "## It can be used to build information extraction or natural language understanding systems, or to pre-process text for deep learning based on [3].\n",
        "import spacy\n",
        "\n",
        "# Import \"en_core_web_sm\" English language model by using spaCy library\n",
        "## It is a small English pipeline trained on written web text (blogs, news, comments), that includes vocabulary, syntax and entities based on [4].\n",
        "## It is optimized for CPU and its components are: tok2vec, tagger, parser, senter, ner, attribute_ruler, lemmatizer based on [5].\n",
        "sp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.** Now, we will create a spaCy document and perform POS tagging.\n",
        "\n",
        "**NOTE:**  When we create a text, spaCy automatically tokenizes the text to produce a Doc object. The Doc is then processed in several different steps (tokenizer, tagger, parser, ner, etc.). This is also referred to as the processing pipeline.\n",
        "\n",
        "You can see the processing pipeline in the following picture based on [[6]](#scrollTo=op-j6UywUt5i).\n",
        "\n",
        "For POS tagging, we will simply use \"pos_\" attribute of the \"Morphologizer\" class in the spaCy. For more detail please refer to [[7]](#scrollTo=op-j6UywUt5i).\n",
        "\n",
        "![spaCy](https://spacy.io/pipeline-fde48da9b43661abcdf62ab70a546d71.svg)"
      ],
      "metadata": {
        "id": "IQRDu2pac7Yc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZw2sdxSpF9v"
      },
      "source": [
        "# Create a sample document\n",
        "## During the document creation process, spaCy will automatically perform POS tagging for the given text.\n",
        "doc_POS = sp(u\"I am going to complete this book by this weekend\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.** Print the POS tags"
      ],
      "metadata": {
        "id": "pK8A81Vcf_wL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsXwhtZepF9x",
        "outputId": "5062a9b5-eab1-4ff7-fbd0-ff2cb728342c"
      },
      "source": [
        "# We will now print each word with its related POS tag.\n",
        "## For this, we will use \"pos_\" attribute of the spaCy.\n",
        "## spaCy predicts the morphological features of a given text.\n",
        "## These predictions are returned by using the \"pos_\" attribute based on [7].\n",
        "for word in doc_POS:\n",
        "    print(word.text + '-->' + word.pos_)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I-->PRON\n",
            "am-->AUX\n",
            "going-->VERB\n",
            "to-->PART\n",
            "complete-->VERB\n",
            "this-->DET\n",
            "book-->NOUN\n",
            "by-->ADP\n",
            "this-->DET\n",
            "weekend-->NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.** If we want, we can also print explanations of the tags.\n",
        "\n",
        "As you will notice, the readability of the output below is much better than in the previous example (step 3).\n",
        "\n",
        "We improve the readability and formatting by columns. The numbers in curly brackets indicate the space between columns [[8]](#scrollTo=op-j6UywUt5i)."
      ],
      "metadata": {
        "id": "6ZAVILFWhYCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will now print each word with its related POS tag and explanation:\n",
        "for word in doc_POS:\n",
        "    print(f'{word.text:{12}} {word.pos_:{10}} {spacy.explain(word.tag_)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glnP0a4Ag98q",
        "outputId": "b71c546d-dd7d-45ee-fa19-1e3df511f040"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I            PRON       pronoun, personal\n",
            "am           AUX        verb, non-3rd person singular present\n",
            "going        VERB       verb, gerund or present participle\n",
            "to           PART       infinitival \"to\"\n",
            "complete     VERB       verb, base form\n",
            "this         DET        determiner\n",
            "book         NOUN       noun, singular or mass\n",
            "by           ADP        conjunction, subordinating or preposition\n",
            "this         DET        determiner\n",
            "weekend      NOUN       noun, singular or mass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3- References**\n",
        "\n",
        "- [1] NLP and Computer Vision_DLMAINLPCV01 Lecture Book\n",
        "- [2] https://spacy.io/\n",
        "- [3] https://spacy.io/usage/spacy-101\n",
        "- [4] https://spacy.io/models\n",
        "- [5] https://spacy.io/models/en\n",
        "- [6] https://spacy.io/usage/processing-pipelines\n",
        "- [7] https://spacy.io/api/morphologizer#section-assigned-attributes\n",
        "- [8] https://stackabuse.com/python-for-nlp-parts-of-speech-tagging-and-named-entity-recognition/"
      ],
      "metadata": {
        "id": "op-j6UywUt5i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kDAQDmXpF91"
      },
      "source": [
        "Copyright © 2021 IU International University of Applied Sciences"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_1_3_bag_of_words.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8kWlZt0q7F5"
      },
      "source": [
        "# Bag-of-Words\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook was prepared to help students improve their coding skills and show code examples of the bag-of-words (BoW) model.\n",
        "\n",
        "Each topic contains two sections:\n",
        "- Definition\n",
        "- Code examples"
      ],
      "metadata": {
        "id": "eOXehIIwUrHe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eotdvPiWuFO"
      },
      "source": [
        "## **1- Introduction**\n",
        "\n",
        "Machine learning algorithms only accept numbers as inputs. How can we extract semantic information from unstructured text and convert it into a numerical input vector that the computer can process? The DLMAINLPCV01 lecture book introduces two methods to embed words and documents into a semantic vector space. The first method is the simple and intuitive bag-of-words approach and the second method is the more powerful neural word and sentence vectors. Neural language models (NLM) use these embeddings of words to make their predictions.\n",
        "\n",
        "In this notebook, you will find code examples for the bag-of-words method. The word vectors are explained in [this notebook](https://colab.research.google.com/github/EmrahYener/DLMAINLPCV01_demo/blob/master/notebooks/nlp_1-3_word_vectors.ipynb).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2- Bag-of-Words**\n",
        "\n",
        "Bag-of-Words (BoW) is a featurization method that uses a vector of word counts (or binary). In this method, the word order is ignored.\n",
        "\n",
        "Most algorithms (kNN, Naïve Bayes, Logistic Regression, kMeans clustering, topic models, collaborative filtering) expect numerical vector inputs. BoW is a simple approach to convert textual information to numbers. In this method, we can represent a given text in the form of a unique set of words (“bag”), i.e. a vector containing word counts of a document.\n",
        "\n"
      ],
      "metadata": {
        "id": "xPanpTPbdGMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Code Examples:**"
      ],
      "metadata": {
        "id": "2a9PY0jSdIdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>1. </b>   The following example shows the following steps:\n",
        "- concatenate all given sentences to one list (\"doc\")\n",
        "- remove any period \".\" mark from the text\n",
        "- iterate through the list \"doc\" and find all unique words in the given sentences\n",
        "- append all unique words to the same list (\"unique_tokens\")"
      ],
      "metadata": {
        "id": "h4Lp79vldKHS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hnkiu6mG6qsz",
        "outputId": "23b38c6d-fb94-40fe-84f7-8c4a16625ebe"
      },
      "source": [
        "# Input sentences\n",
        "s1=\"Federer is one of the greatest tennis players of all time.\"\n",
        "s2=\"Federer has won twenty grand slam titles to date.\"\n",
        "\n",
        "# Find unique word tokens for both sentences\n",
        "\n",
        "## Remove '.' and concatenate the sentences to 1 list\n",
        "doc = s1.replace('.','').split() + s2.replace('.','').split()\n",
        "\n",
        "## Build an unordered collection of unique elements\n",
        "oc = set()\n",
        "\n",
        "## Iterate through the document and collect the unique elements\n",
        "unique_tokens = [\n",
        "                 t for t in doc if not (t in oc or oc.add(t))\n",
        "                ] \n",
        "\n",
        "\n",
        "print(unique_tokens)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Federer', 'is', 'one', 'of', 'the', 'greatest', 'tennis', 'players', 'all', 'time', 'has', 'won', 'twenty', 'grand', 'slam', 'titles', 'to', 'date']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzxwvaK7OPFs"
      },
      "source": [
        "<br></br>\n",
        "<b>2. </b>   The following example shows how to calculate the frequency of each word in a given sentence: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGF-n6l5FcMS",
        "outputId": "2573b886-766d-4e90-b7b8-d04628939d78"
      },
      "source": [
        "# Count the frequency of each unique word token in sentence s1\n",
        "\n",
        "## Create an empty list to use as a vector\n",
        "vec_1 = []\n",
        "\n",
        "## Delete the period \".\" from the sentence s1 and append each word to the list token_1\n",
        "token_1 = s1.replace('.','').split()\n",
        "\n",
        "\n",
        "## Iterate through \"unique_tokens\", compare each word with the words in \"token_1\" and count the frequency of each word\n",
        "for t in unique_tokens:\n",
        "  count = token_1.count(t)\n",
        "  print(f'{t}: {count}')\n",
        "  vec_1.append(count)\n",
        "\n",
        "print(f'\\nVector ouput:\\n{s1}\\n{vec_1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Federer: 1\n",
            "is: 1\n",
            "one: 1\n",
            "of: 2\n",
            "the: 1\n",
            "greatest: 1\n",
            "tennis: 1\n",
            "players: 1\n",
            "all: 1\n",
            "time: 1\n",
            "has: 0\n",
            "won: 0\n",
            "twenty: 0\n",
            "grand: 0\n",
            "slam: 0\n",
            "titles: 0\n",
            "to: 0\n",
            "date: 0\n",
            "\n",
            "vector ouput\n",
            "Federer is one of the greatest tennis players of all time.\n",
            "[1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugB8f6YZHlNL",
        "outputId": "25d06ce4-692d-4a4e-b50f-b7fb093afd0c"
      },
      "source": [
        "# Count the frequency of each unique word token in sentence s2\n",
        "\n",
        "## We will follow the same steps as for sentence s1\n",
        "\n",
        "vec_2 = []\n",
        "\n",
        "token_2 = s2.replace('.','').split()\n",
        "\n",
        "for t in unique_tokens:\n",
        "  count = token_2.count(t)\n",
        "  print(f'{t}: {count}')\n",
        "  vec_2.append(count)\n",
        "\n",
        "print(f'\\nVector ouput:\\n{s2}\\n{vec_2}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Federer: 1\n",
            "is: 0\n",
            "one: 0\n",
            "of: 0\n",
            "the: 0\n",
            "greatest: 0\n",
            "tennis: 0\n",
            "players: 0\n",
            "all: 0\n",
            "time: 0\n",
            "has: 1\n",
            "won: 1\n",
            "twenty: 1\n",
            "grand: 1\n",
            "slam: 1\n",
            "titles: 1\n",
            "to: 1\n",
            "date: 1\n",
            "\n",
            "vector ouput\n",
            "Federer has won twenty grand slam titles to date.\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfo10R9HO7fg"
      },
      "source": [
        "<br></br>\n",
        "<b>3. </b>   We have seen how to find unique words in a given text and the frequency of each word. The following example shows how to print frequency data as a bag-of-words vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwQ7y9kjHwbw",
        "outputId": "15fd075b-e98d-49a7-c24b-f38458104f7f"
      },
      "source": [
        "# Print each sentence together with its corresponding vector\n",
        "print(f'\\n{s1}\\n{vec_1}')\n",
        "print(f'\\n{s2}\\n{vec_2}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Federer is one of the greatest tennis players of all time.\n",
            "[1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "Federer has won twenty grand slam titles to date.\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "source": [
        "Copyright © 2021 IU International University of Applied Sciences"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "uBItSFhfUDOB"
      }
    }
  ]
}
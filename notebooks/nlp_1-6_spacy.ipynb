{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "colab": {
      "name": "nlp_1-6_spacy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_X42HQ1pF84"
      },
      "source": [
        "## **NLP with spaCy**\n",
        "\n",
        "SpaCy is one of the most famous framework for NLP. It can be used for the implementation of tasks for sentiment analysis, chatbots, text summarization, intent and entity extraction, and others.\n",
        "\n",
        "More information about spaCy:  [www.spacy.io](https://spacy.io/)\n",
        "\n",
        "In this notebook some basic examples for following topics are shown:\n",
        "- Tokenization\n",
        "- Sentence Tokenization\n",
        "- Part-Of-Speach Tagging\n",
        "- named entity recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rVtW6JEpF9f"
      },
      "source": [
        "# Load resources for all following code cells\n",
        "import spacy\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "sp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CPahqp-pF9i"
      },
      "source": [
        "#### **Word-Tokenization**\n",
        "\n",
        "Access the word tokens by iterating over the document object ``doc`` and print them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n_iU6SVpF9k",
        "outputId": "9d469516-c297-497e-a0d5-791f885f249a"
      },
      "source": [
        "# Create document\n",
        "doc = sp(u'I am non-vegetarian, send me the menu at abs-xyz@gmail.com. \"They are going to U.K. and the to the U.S.A\"')\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I\n",
            "am\n",
            "non\n",
            "-\n",
            "vegetarian\n",
            ",\n",
            "send\n",
            "me\n",
            "the\n",
            "menu\n",
            "at\n",
            "abs-xyz@gmail.com\n",
            ".\n",
            "\"\n",
            "They\n",
            "are\n",
            "going\n",
            "to\n",
            "U.K.\n",
            "and\n",
            "the\n",
            "to\n",
            "the\n",
            "U.S.A\n",
            "\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV0iRL_ZpF9o"
      },
      "source": [
        "#### **Sentence-Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYFYuprlpF9q",
        "outputId": "3eee08e1-0948-405c-b7b9-d6e2ab5cb00e"
      },
      "source": [
        "# Print the whole sentences from the document 'doc'\n",
        "for sentence in doc.sents:\n",
        "    print(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am non-vegetarian, send me the menu at abs-xyz@gmail.com.\n",
            "\"They are going to U.K. and the to the U.S.A\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyo5PWLBpF9s"
      },
      "source": [
        "#### **Part-Of-Speech (POS) tagging**\n",
        "\n",
        "To output POS tags in spaCy, we iterate over the word token in our document ``doc_POS`` and print out the ``pos_`` attribute of each token\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZw2sdxSpF9v"
      },
      "source": [
        "# Create POS document\n",
        "doc_POS = sp(u\"I am going to complete this book by this weekend\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsXwhtZepF9x",
        "outputId": "cc5fd13b-95a0-499e-ffca-49b6cbf5a2e4"
      },
      "source": [
        "# Show the found POS items\n",
        "for word in doc_POS:\n",
        "    print(word.text + '-->' + word.pos_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I-->PRON\n",
            "am-->AUX\n",
            "going-->VERB\n",
            "to-->PART\n",
            "complete-->VERB\n",
            "this-->DET\n",
            "book-->NOUN\n",
            "by-->ADP\n",
            "this-->DET\n",
            "weekend-->NOUN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3KClYAYpF9y"
      },
      "source": [
        "#### **Named Entity Recognition (NER)**\n",
        "\n",
        "To output named entity labels in spaCy, we just have to iterate over the entities in our document ``doc_ner`` and print out the ``label_`` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KRXu4WQpF90",
        "outputId": "cfff2f5e-7054-4ec5-8aff-b8933fb64921"
      },
      "source": [
        "# Create NER document\n",
        "doc_ner = sp(u'Christiano Ronaldo was signed by Juventus for $105 million')\n",
        "\n",
        "for entity in doc_ner.ents:\n",
        "    print(entity.text + ' - ' \n",
        "          + entity.label_ + ' - ' \n",
        "          + str(spacy.explain(entity.label_)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Christiano Ronaldo - PERSON - People, including fictional\n",
            "Juventus - ORG - Companies, agencies, institutions, etc.\n",
            "$105 million - MONEY - Monetary values, including unit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kDAQDmXpF91"
      },
      "source": [
        "Copyright Â© 2021 IU International University of Applied Sciences"
      ]
    }
  ]
}
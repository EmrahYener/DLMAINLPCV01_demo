{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "colab": {
      "name": "nlp_1-6_spacy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_X42HQ1pF84"
      },
      "source": [
        "**NLP with spaCy**\n",
        "\n",
        "SpaCy is one of the most famous framework for NLP. It can be used for the implementation of tasks for sentiment analysis, chatbots, text summarization, intent and entity extraction, and others.\n",
        "\n",
        "In this notebook some basic examples for following topics are shown:\n",
        "- [Tokenization](#tokenization)\n",
        "- [Sentence Tokenization](#sentence_tokenization)\n",
        "- [Part-Of-Speach Tagging](#pos_tagging)\n",
        "- [named entity recognition](#ner)\n",
        "\n",
        "mor information about spaCy:  [www.spacy.io](https://spacy.io/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rVtW6JEpF9f"
      },
      "source": [
        "# load resources for all following code cells\n",
        "import spacy\n",
        "#\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CPahqp-pF9i"
      },
      "source": [
        "<a id=tokenization></a>**Tokenization**\n",
        "\n",
        "access the word tokens by iterating over the document object doc and print them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n_iU6SVpF9k",
        "outputId": "9d469516-c297-497e-a0d5-791f885f249a"
      },
      "source": [
        "# create document\n",
        "doc = sp(u'I am non-vegetarian, send me the menu at abs-xyz@gmail.com. \"They are going to U.K. and the to the U.S.A\"')\n",
        "#\n",
        "for token in doc:\n",
        "    print(token.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I\n",
            "am\n",
            "non\n",
            "-\n",
            "vegetarian\n",
            ",\n",
            "send\n",
            "me\n",
            "the\n",
            "menu\n",
            "at\n",
            "abs-xyz@gmail.com\n",
            ".\n",
            "\"\n",
            "They\n",
            "are\n",
            "going\n",
            "to\n",
            "U.K.\n",
            "and\n",
            "the\n",
            "to\n",
            "the\n",
            "U.S.A\n",
            "\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV0iRL_ZpF9o"
      },
      "source": [
        "<a id=sentence_tokenization></a>**Sentence tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYFYuprlpF9q",
        "outputId": "3eee08e1-0948-405c-b7b9-d6e2ab5cb00e"
      },
      "source": [
        "for sentence in doc.sents:\n",
        "    print(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am non-vegetarian, send me the menu at abs-xyz@gmail.com.\n",
            "\"They are going to U.K. and the to the U.S.A\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyo5PWLBpF9s"
      },
      "source": [
        "<a id=pos_tagging></a>**part-of-speech (POS) tagging**\n",
        "\n",
        "to output POS tags in spaCy, we iterate over the word token in our document ``doc_POS`` and print out the ``pos_`` attribute of each token\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZw2sdxSpF9v"
      },
      "source": [
        "doc_POS = sp(u\"I am going to complete this book by this weekend\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsXwhtZepF9x",
        "outputId": "cc5fd13b-95a0-499e-ffca-49b6cbf5a2e4"
      },
      "source": [
        "for word in doc_POS:\n",
        "    print(word.text + '-->' + word.pos_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I-->PRON\n",
            "am-->AUX\n",
            "going-->VERB\n",
            "to-->PART\n",
            "complete-->VERB\n",
            "this-->DET\n",
            "book-->NOUN\n",
            "by-->ADP\n",
            "this-->DET\n",
            "weekend-->NOUN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3KClYAYpF9y"
      },
      "source": [
        "<a id=ner></a>**named entity recognition (NER)**\n",
        "\n",
        "to output named entity labels in spaCy we just have to iterate over the entities in our document ``doc.ents`` and print out the ``label_`` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KRXu4WQpF90",
        "outputId": "cfff2f5e-7054-4ec5-8aff-b8933fb64921"
      },
      "source": [
        "doc_ner = sp(u'Christiano Ronaldo was signed by Juventus for $105 million')\n",
        "#\n",
        "for entity in doc_ner.ents:\n",
        "    print(entity.text + ' - ' \n",
        "          + entity.label_ + ' - ' \n",
        "          + str(spacy.explain(entity.label_)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Christiano Ronaldo - PERSON - People, including fictional\n",
            "Juventus - ORG - Companies, agencies, institutions, etc.\n",
            "$105 million - MONEY - Monetary values, including unit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kDAQDmXpF91"
      },
      "source": [
        "Copyright Â© 2021 IUBH Internationale Hochschule"
      ]
    }
  ]
}
